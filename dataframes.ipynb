{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "railway_data = pd.read_excel('../COVID_complete_data.xlsx', sheet_name=\"RAILWAY\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrival_date = 'Travel Date'\n",
    "departure_date = 'Journey start date'\n",
    "train_id = 'Train No'\n",
    "origin_district = 'Origin District'\n",
    "destination_district = 'Destination District'\n",
    "tmc_or_home = 'TMC/home'\n",
    "age = 'Age'\n",
    "gender = 'Gender'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = railway_data.shape[0]\n",
    "mydict = dict()\n",
    "keys = []\n",
    "row_list = []\n",
    "for i in range(nrows):\n",
    "    row = railway_data.loc[i]\n",
    "    key = (row['Travel Date'], row[train_id], row[destination_district])\n",
    "    \n",
    "    if key in mydict:\n",
    "        nrow = mydict[key]\n",
    "    else:                \n",
    "        nrow = dict()\n",
    "        nrow['Arrival Date'] = row['Travel Date'].date()\n",
    "        nrow['Destination District'] = row[destination_district]\n",
    "        nrow['Train ID'] = row[train_id]\n",
    "        nrow['Departure Date'] = row['Journey start date'].date()\n",
    "        nrow['Origin District'] = row['Origin District']\n",
    "        nrow['Origin State'] = row['Origin State']\n",
    "        nrow['Number of passengers'] = 0\n",
    "        nrow['Age group (0-14)'] = 0\n",
    "        nrow['Age group (15-40)'] = 0\n",
    "        nrow['Age group (41-60)'] = 0\n",
    "        nrow['Age group (60+)'] = 0\n",
    "        nrow['Number of males'] = 0\n",
    "        nrow['Number of females'] = 0\n",
    "        nrow['N_TMC_quarantined'] = 0\n",
    "        nrow['N_Other_quarantined'] = 0\n",
    "        mydict[key] = nrow\n",
    "        row_list.append(nrow)\n",
    "        \n",
    "\n",
    "    nrow['Number of passengers'] += 1\n",
    "    if row[age] <= 14:\n",
    "        nrow['Age group (0-14)'] += 1\n",
    "    elif row[age] <= 40:\n",
    "        nrow['Age group (15-40)'] += 1\n",
    "    elif row[age] <= 40:\n",
    "        nrow['Age group (41-60)'] += 1\n",
    "    else:\n",
    "        nrow['Age group (60+)'] += 1\n",
    "    if row[gender] == 'Male':\n",
    "        nrow['Number of males'] += 1\n",
    "    else: \n",
    "        nrow['Number of females'] += 1\n",
    "    if tmc_or_home == 'TMC':\n",
    "        nrow['N_TMC_quarantined'] += 1\n",
    "    else:\n",
    "        nrow['N_Other_quarantined'] += 1\n",
    "        \n",
    "        \n",
    "#     print(row[3])\n",
    "#     if \n",
    "#     print(row[train_id])\n",
    "#     mydict[] \n",
    "    \n",
    "# print(mydict)\n",
    "# row = railway_data.loc[1]\n",
    "# print(railway_data.loc[1,train_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeDFToExcel(row_list, excel_file_name, excel_sheet_name):\n",
    "    df = pd.DataFrame(row_list)\n",
    "    print(len(row_list))\n",
    "    # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "    writer = pd.ExcelWriter(excel_file_name, engine='xlsxwriter')\n",
    "\n",
    "    # Convert the dataframe to an XlsxWriter Excel object.\n",
    "    df.to_excel(writer, sheet_name=excel_sheet_name)\n",
    "\n",
    "    # Close the Pandas Excel writer and output the Excel file.\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4850\n"
     ]
    }
   ],
   "source": [
    "writeDFToExcel(row_list, 'covid_processed_railways.xlsx', 'Railways')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "railway_data.shape[0]\n",
    "type(row[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_data = pd.read_excel('../COVID_complete_data.xlsx', sheet_name=\"ROADWAYS\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_type = 'Vehicle Type'\n",
    "vehicle_id = 'Vehicle No'\n",
    "arrival_date = 'Checkin Date'\n",
    "nrows = road_data.shape[0]\n",
    "mydict = dict()\n",
    "row_list = []\n",
    "for i in range(nrows):\n",
    "    row = road_data.loc[i]\n",
    "    key = (row[vehicle_id], row[destination_district])\n",
    "    \n",
    "    if key in mydict:\n",
    "        nrow = mydict[key]\n",
    "    else:                \n",
    "        nrow = dict()\n",
    "        mydate = row['Checkin Date']\n",
    "        if pd.isna(mydate):\n",
    "            mydate = row['Journey start date']            \n",
    "#             mydate = datetime.strptime(mydate,'%d-%b-%Y')\n",
    "            mydate = mydate.date()        \n",
    "        elif isinstance(mydate, str):\n",
    "            mydate = mydate[:10]\n",
    "            mydate = datetime.strptime(mydate,'%Y-%m-%d')\n",
    "            mydate = mydate.date()\n",
    "        else:\n",
    "            mydate = mydate.date()\n",
    "\n",
    "        nrow['Arrival Date'] = mydate\n",
    "        nrow['Destination District'] = row[destination_district]\n",
    "        nrow['Vehicle No'] = row[vehicle_id]\n",
    "        nrow['Departure Date'] = row[departure_date].date()        \n",
    "        nrow['Origin District'] = row[origin_district]\n",
    "        nrow['Origin State'] = row['Origin State']\n",
    "        nrow['Number of passengers'] = 0\n",
    "        nrow['Age group (0-14)'] = 0\n",
    "        nrow['Age group (15-40)'] = 0\n",
    "        nrow['Age group (41-60)'] = 0\n",
    "        nrow['Age group (60+)'] = 0\n",
    "        nrow['Number of males'] = 0\n",
    "        nrow['Number of females'] = 0\n",
    "        nrow['N_TMC_quarantined'] = 0\n",
    "        nrow['N_Other_quarantined'] = 0\n",
    "        nrow['N_buses'] = 0\n",
    "        nrow['N_4-Wheeler'] = 0\n",
    "        nrow['N_2-Wheeler'] = 0\n",
    "        \n",
    "        mydict[key] = nrow\n",
    "        row_list.append(nrow)\n",
    "        \n",
    "\n",
    "    nrow['Number of passengers'] += 1\n",
    "    if row[age] <= 14:\n",
    "        nrow['Age group (0-14)'] += 1\n",
    "    elif row[age] <= 40:\n",
    "        nrow['Age group (15-40)'] += 1\n",
    "    elif row[age] <= 40:\n",
    "        nrow['Age group (41-60)'] += 1\n",
    "    else:\n",
    "        nrow['Age group (60+)'] += 1\n",
    "    if row[gender] == 'Male':\n",
    "        nrow['Number of males'] += 1\n",
    "    else: \n",
    "        nrow['Number of females'] += 1\n",
    "    if tmc_or_home == 'TMC':\n",
    "        nrow['N_TMC_quarantined'] += 1\n",
    "    else:\n",
    "        nrow['N_Other_quarantined'] += 1\n",
    "\n",
    "    if row['Vehicle Type'] == 'Bus':\n",
    "        nrow['N_buses'] += 1\n",
    "    elif row['Vehicle Type'] == '4-Wheeler':\n",
    "        nrow['N_4-Wheeler'] += 1\n",
    "    elif row['Vehicle Type'] == '2-Wheeler':\n",
    "        nrow['N_2-Wheeler'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30235\n"
     ]
    }
   ],
   "source": [
    "writeDFToExcel(row_list, 'covid_processed_roadways.xlsx', 'Roadways')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "airways_data = pd.read_excel('../COVID_complete_data.xlsx', sheet_name=\"AIRWAYS-DOMESTIC\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = airways_data.shape[0]\n",
    "arrival_date = 'Travel Date'\n",
    "flight_id = 'Flight No'\n",
    "mydict = dict()\n",
    "keys = []\n",
    "row_list = []\n",
    "for i in range(nrows):\n",
    "    row = airways_data.loc[i]\n",
    "    key = (row[arrival_date], row[flight_id], row[destination_district])\n",
    "    \n",
    "    if key in mydict:\n",
    "        nrow = mydict[key]\n",
    "    else:                \n",
    "        nrow = dict()\n",
    "        nrow['Arrival Date'] = row[arrival_date]\n",
    "        nrow['Destination District'] = row[destination_district]\n",
    "        nrow['Flight ID'] = row[flight_id]\n",
    "        nrow['Departure Date'] = row[departure_date]\n",
    "        nrow['Origin District'] = row[origin_district]\n",
    "        nrow['Number of passengers'] = 0\n",
    "        nrow['Age group (0-14)'] = 0\n",
    "        nrow['Age group (15-40)'] = 0\n",
    "        nrow['Age group (41-60)'] = 0\n",
    "        nrow['Age group (60+)'] = 0\n",
    "        nrow['Number of males'] = 0\n",
    "        nrow['Number of females'] = 0\n",
    "        nrow['N_TMC_quarantined'] = 0\n",
    "        nrow['N_Other_quarantined'] = 0\n",
    "        mydict[key] = nrow\n",
    "        row_list.append(nrow)\n",
    "        \n",
    "\n",
    "    nrow['Number of passengers'] += 1\n",
    "    if row[age] <= 14:\n",
    "        nrow['Age group (0-14)'] += 1\n",
    "    elif row[age] <= 40:\n",
    "        nrow['Age group (15-40)'] += 1\n",
    "    elif row[age] <= 40:\n",
    "        nrow['Age group (41-60)'] += 1\n",
    "    else:\n",
    "        nrow['Age group (60+)'] += 1\n",
    "    if row[gender] == 'Male':\n",
    "        nrow['Number of males'] += 1\n",
    "    else: \n",
    "        nrow['Number of females'] += 1\n",
    "#     if tmc_or_home == 'TMC':\n",
    "#         nrow['N_TMC_quarantined'] += 1\n",
    "#     else:\n",
    "#         nrow['N_Other_quarantined'] += 1\n",
    "    nrow['N_Other_quarantined'] += 1 # all flight passengers were home quarantined  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "writeDFToExcel(row_list, 'covid_processed_airways.xlsx', 'Airways')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmc_data = pd.read_excel('../COVID_complete_data.xlsx', sheet_name=\"TMC_full\", skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sl No</th>\n",
       "      <th>District</th>\n",
       "      <th>Block</th>\n",
       "      <th>TMC Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Number of people in TMC</th>\n",
       "      <th>Maximum Capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ANUGUL</td>\n",
       "      <td>PALALAHADA</td>\n",
       "      <td>ACCHUTANANDA A S INJID</td>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ANUGUL</td>\n",
       "      <td>PALALAHADA</td>\n",
       "      <td>ACCHUTANANDA A S INJID</td>\n",
       "      <td>2020-04-11</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ANUGUL</td>\n",
       "      <td>PALALAHADA</td>\n",
       "      <td>ACCHUTANANDA A S INJID</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ANUGUL</td>\n",
       "      <td>PALALAHADA</td>\n",
       "      <td>ACCHUTANANDA A S INJID</td>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ANUGUL</td>\n",
       "      <td>PALALAHADA</td>\n",
       "      <td>ACCHUTANANDA A S INJID</td>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sl No District       Block                TMC Name       Date  \\\n",
       "0      1   ANUGUL  PALALAHADA  ACCHUTANANDA A S INJID 2020-04-10   \n",
       "1      2   ANUGUL  PALALAHADA  ACCHUTANANDA A S INJID 2020-04-11   \n",
       "2      3   ANUGUL  PALALAHADA  ACCHUTANANDA A S INJID 2020-04-12   \n",
       "3      4   ANUGUL  PALALAHADA  ACCHUTANANDA A S INJID 2020-04-12   \n",
       "4      5   ANUGUL  PALALAHADA  ACCHUTANANDA A S INJID 2020-04-13   \n",
       "\n",
       "   Number of people in TMC  Maximum Capacity  \n",
       "0                        1                 4  \n",
       "1                        1                20  \n",
       "2                        1                20  \n",
       "3                        1               316  \n",
       "4                        1                20  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = tmc_data.shape[0]\n",
    "mydict = dict()\n",
    "row_list = []\n",
    "for i in range(nrows):\n",
    "    row = tmc_data.loc[i]\n",
    "#     print(row)\n",
    "    key = (row['Date'], row['District'])\n",
    "    \n",
    "    if key in mydict:\n",
    "        nrow = mydict[key]\n",
    "    else:                \n",
    "        nrow = dict()\n",
    "        nrow['District'] = row['District']\n",
    "        nrow['Date'] = row['Date']        \n",
    "        nrow['Number of TMCs'] = 0\n",
    "        nrow['Total capacity'] = 0\n",
    "        nrow['Total occupancy '] = 0\n",
    "        mydict[key] = nrow\n",
    "        row_list.append(nrow)\n",
    "        \n",
    "    nrow['Number of TMCs'] += 1\n",
    "    nrow['Total capacity'] += row['Maximum Capacity']\n",
    "    nrow['Total occupancy '] += row['Number of people in TMC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "writeDFToExcel(row_list, 'covid_processed_tmc.xlsx', 'TMC_district')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data = pd.read_excel('../COVID_complete_data.xlsx', sheet_name=\"Positive Cases\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nrows = covid_data.shape[0]\n",
    "mydict = dict()\n",
    "row_list = []\n",
    "myrows = nrows\n",
    "for i in range(myrows):\n",
    "    row = covid_data.loc[i]\n",
    "    \n",
    "    key = (row['Date of  declared Positive'], row['District'])    \n",
    "    if type(row['Date of  declared Positive']) != pd._libs.tslibs.timestamps.Timestamp:\n",
    "        print(i, \"Date is empty\", row['Date of  declared Positive'])\n",
    "        continue\n",
    "    if row['District'] == '':\n",
    "        print(i, \"District is empty\", row['District'])\n",
    "        continue\n",
    "        \n",
    "    if key in mydict:\n",
    "        nrow = mydict[key]\n",
    "    else:                \n",
    "        nrow = dict()\n",
    "        nrow['District'] = row['District']\n",
    "        nrow['Date'] = row['Date of  declared Positive']        \n",
    "        nrow['Positive cases'] = 0\n",
    "        nrow['Negative cases'] = 0\n",
    "        nrow['Total positive males'] = 0\n",
    "        nrow['Total positive females'] = 0        \n",
    "        nrow['Age group (0-14)'] = 0\n",
    "        nrow['Age group (15-40)'] = 0\n",
    "        nrow['Age group (41-60)'] = 0\n",
    "        nrow['Age group (60+)'] = 0\n",
    "        nrow['Symptomatic'] = 0\n",
    "        nrow['Asymptomatic'] = 0\n",
    "        nrow['Recovered'] = 0\n",
    "        nrow['Deaths'] = 0\n",
    "\n",
    "        mydict[key] = nrow\n",
    "        row_list.append(nrow)\n",
    "        \n",
    "    nrow['Positive cases'] += 1\n",
    "\n",
    "    try: \n",
    "        if row[age] <= 14:\n",
    "            nrow['Age group (0-14)'] += 1\n",
    "        elif row[age] <= 40:\n",
    "            nrow['Age group (15-40)'] += 1\n",
    "        elif row[age] <= 40:\n",
    "            nrow['Age group (41-60)'] += 1\n",
    "        else:\n",
    "            nrow['Age group (60+)'] += 1        \n",
    "    except:        \n",
    "        print(\"Exception occurred\", i, row[age])\n",
    "        \n",
    "    if row['Sex'] == 'Male':\n",
    "        nrow['Total positive males'] += 1\n",
    "    else: \n",
    "        nrow['Total positive females'] += 1\n",
    "    if row['Symptomatic (yes/no)'] == 'Symptomatic':\n",
    "        nrow['Symptomatic'] += 1\n",
    "    else: \n",
    "        nrow['Asymptomatic'] += 1\n",
    "\n",
    "for i in range(myrows):\n",
    "    row = covid_data.loc[i]\n",
    "    key = (row['Recovery/Death date'], row['District'])    \n",
    "    if type(row['Recovery/Death date']) != pd._libs.tslibs.timestamps.Timestamp:\n",
    "        print(i, \"Date is empty\", row['Recovery/Death date'])\n",
    "        continue\n",
    "        \n",
    "    if key in mydict:\n",
    "        nrow = mydict[key]\n",
    "        \n",
    "        if row['Recovered (yes/no)'] == 'Recovered':\n",
    "            nrow['Recovered'] += 1\n",
    "        elif row['Recovered (yes/no)'] == 'Death':\n",
    "            nrow['Deaths'] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(myrows):\n",
    "    row = covid_data.loc[i]\n",
    "    key = (row['Recovery/Death date'], row['District'])    \n",
    "    if key in mydict:\n",
    "        nrow = mydict[key]\n",
    "        \n",
    "        if nrow['Deaths'] > 1500:\n",
    "            print(i, nrow['Date'], nrow['District'], nrow)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1883\n"
     ]
    }
   ],
   "source": [
    "writeDFToExcel(row_list, 'covid_processed_covid.xlsx', 'COVID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = covid_data.loc[1]\n",
    "type(row['Recovery/Death date'])\n",
    "type(row['Recovery/Death date']) == pd._libs.tslibs.timestamps.Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "directory = '../district level data'\n",
    "row_list = []\n",
    "i = 0\n",
    "filename = ''\n",
    "for filename in os.listdir(directory):\n",
    "    i += 1    \n",
    "    print(\"Doing\",i,filename)\n",
    "#     if i > 1:\n",
    "#         break\n",
    "    if filename.endswith(\".xlsx\"):\n",
    "        book = openpyxl.load_workbook(directory+'/'+filename)\n",
    "        sheet = book.active\n",
    "        nrow = dict()\n",
    "        nrow['District'] = filename[:-5]\n",
    "        nrow['Area'] = 0\n",
    "        nrow['Population'] = 0\n",
    "        nrow['Sex Ratio (Number of females per 1000 males) - Total'] = sheet['E5'].value\n",
    "        nrow['Sex Ratio (Number of females per 1000 males) - Rural'] = sheet['H5'].value\n",
    "        nrow['Sex Ratio (Number of females per 1000 males) - Urban'] = sheet['K5'].value\n",
    "        nrow['Total Literacy Rate'] = sheet['F31'].value\n",
    "        nrow['Male Literacy Rate'] = sheet['I31'].value\n",
    "        nrow['Female Literacy Rate'] = sheet['L31'].value\n",
    "        nrow['Net enrollment (Primary)'] = sheet['E34'].value\n",
    "        nrow['Net enrollment (Upper-Primary)'] = sheet['I34'].value\n",
    "        nrow['Drop out rate (Primary)'] = sheet['E35'].value\n",
    "        nrow['Drop out rate (Upper-Primary)'] = sheet['I35'].value\n",
    "        totalHouseholds = sheet['E48'].value\n",
    "        ruralHouseholds = sheet['H48'].value\n",
    "        urbanHouseholds = sheet['K48'].value\n",
    "        nrow['Total Households in District'] = totalHouseholds\n",
    "        nrow['Rural Households in District'] = ruralHouseholds\n",
    "        nrow['Urban Households in District'] = urbanHouseholds\n",
    "        nrow['Total Households with no lighting (in %)'] = sheet['F52'].value / totalHouseholds * 100\n",
    "        nrow['Rural Households with no lighting (in %)'] = sheet['I52'].value / ruralHouseholds * 100\n",
    "        nrow['Urban Households with no lighting (in %)'] = sheet['L52'].value / urbanHouseholds * 100\n",
    "        nrow['Total Households receiving untreated tap water within premises (in %)'] = sheet['F60'].value / totalHouseholds * 100\n",
    "        nrow['Rural Households receiving untreated tap water within premises (in %)'] = sheet['I60'].value / ruralHouseholds * 100\n",
    "        nrow['Urban Households receiving untreated tap water within premises (in %)'] = sheet['L60'].value / urbanHouseholds * 100\n",
    "        nrow['Total Households with mobile phone (%)'] = sheet['E64'].value\n",
    "        nrow['Rural Households with mobile phone (%)'] = sheet['H64'].value\n",
    "        nrow['Urban Households with mobile phone (%)'] = sheet['K64'].value\n",
    "        nrow['Total Households with computer/laptop with internet connection (%)'] = sheet['E65'].value\n",
    "        nrow['Rural Households with computer/laptop with internet connection (%)'] = sheet['H65'].value\n",
    "        nrow['Urban Households with computer/laptop with internet connection (%)'] = sheet['K65'].value\n",
    "        \n",
    "        row_list.append(nrow)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    print(\"Done\",i,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "writeDFToExcel(row_list, 'covid_processed_confounder.xlsx', 'Confounders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../district level data'\n",
    "row_list = []\n",
    "i = 0\n",
    "filename = ''\n",
    "for filename in os.listdir(directory):\n",
    "    i += 1    \n",
    "    print(\"Doing\",i,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>State</th>\n",
       "      <th>District</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Deceased</th>\n",
       "      <th>Other</th>\n",
       "      <th>Tested</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2679.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Anantapur</td>\n",
       "      <td>53</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Chittoor</td>\n",
       "      <td>73</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>East Godavari</td>\n",
       "      <td>39</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Guntur</td>\n",
       "      <td>214</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                        State       District  Confirmed  \\\n",
       "0  2020-04-26  Andaman and Nicobar Islands        Unknown         33   \n",
       "1  2020-04-26               Andhra Pradesh      Anantapur         53   \n",
       "2  2020-04-26               Andhra Pradesh       Chittoor         73   \n",
       "3  2020-04-26               Andhra Pradesh  East Godavari         39   \n",
       "4  2020-04-26               Andhra Pradesh         Guntur        214   \n",
       "\n",
       "   Recovered  Deceased  Other  Tested  \n",
       "0         11         0      0  2679.0  \n",
       "1         14         4      0     NaN  \n",
       "2         13         0      0     NaN  \n",
       "3         12         0      0     NaN  \n",
       "4         29         8      0     NaN  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "districts = pd.read_csv('../data/Districts.csv')\n",
    "districts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>State</th>\n",
       "      <th>District</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Deceased</th>\n",
       "      <th>Other</th>\n",
       "      <th>Tested</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>Balasore</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>Bhadrak</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>Cuttack</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>Dhenkanal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>Jajpur</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date   State   District  Confirmed  Recovered  Deceased  Other  \\\n",
       "242  2020-04-26  Odisha   Balasore         10          0         0      0   \n",
       "243  2020-04-26  Odisha    Bhadrak         16          2         0      0   \n",
       "244  2020-04-26  Odisha    Cuttack          1          1         0      0   \n",
       "245  2020-04-26  Odisha  Dhenkanal          1          1         0      0   \n",
       "246  2020-04-26  Odisha     Jajpur         18          1         0      0   \n",
       "\n",
       "     Tested  \n",
       "242     NaN  \n",
       "243     NaN  \n",
       "244     NaN  \n",
       "245     NaN  \n",
       "246     NaN  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odisha_districts = districts[districts['State'] =='Odisha']\n",
    "odisha_districts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts = pd.read_excel('../data/Districts_new.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_excel('../COVID_complete_data.xlsx', sheet_name=\"Number of Tests Done\", skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "nrows = districts.shape[0]\n",
    "mydict = dict()\n",
    "row_list = []\n",
    "myrows = nrows\n",
    "for i in range(myrows):\n",
    "    row = districts.loc[i]\n",
    "    if row['State'] != 'Odisha':\n",
    "        continue\n",
    "    \n",
    "    key = row['Date']\n",
    "    key = key.date()\n",
    "    if key in mydict:\n",
    "        nrow = mydict[key]\n",
    "    else:                \n",
    "        nrow = dict()\n",
    "        nrow['Date'] = key\n",
    "#         nrow['Positive cases'] = 0\n",
    "        nrow['Recovered'] = 0\n",
    "        nrow['Deceased'] = 0\n",
    "#         nrow['Total Tested'] = 0\n",
    "#         nrow['Negative cases'] = 0\n",
    "        nrow['Train passengers'] = 0\n",
    "        nrow['Road passengers'] = 0\n",
    "        nrow['Air passengers'] = 0\n",
    "        nrow['Total_TMC_capacity'] = 0\n",
    "        nrow['Total_TMC_occupants'] = 0\n",
    "        mydict[key] = nrow\n",
    "        row_list.append(nrow)\n",
    "    \n",
    "#     nrow['Positive cases'] += row['Confirmed']\n",
    "    nrow['Recovered'] += row['Recovered']\n",
    "    nrow['Deceased'] += row['Deceased']\n",
    "\n",
    "nrows = test_data.shape[0]\n",
    "myrows = nrows\n",
    "for i in range(myrows-3):\n",
    "    row = test_data.loc[i]\n",
    "    key = row['Date/District']\n",
    "    try:\n",
    "        key = key.date()\n",
    "    except:\n",
    "        print(i, key)\n",
    "    if key in mydict:        \n",
    "        nrow = mydict[key]\n",
    "        nrow['Total Tested'] = row['Total Testing']\n",
    "        nrow['Positive cases'] = row['Total Positive']\n",
    "        nrow['Negative cases'] = row['Total Negative']\n",
    "    \n",
    "    \n",
    "print(len(row_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "processed_railway_data = pd.read_excel('covid_processed.xlsx',sheet_name='Railways')\n",
    "nrows = processed_railway_data.shape[0]\n",
    "myrows = nrows\n",
    "for i in range(myrows):\n",
    "    row = processed_railway_data.loc[i]\n",
    "    key = row['Arrival Date']\n",
    "    try:\n",
    "        key = key.date()\n",
    "    except:\n",
    "        print(\"rail\",i, key)\n",
    "    if key in mydict:        \n",
    "        nrow = mydict[key]\n",
    "        nrow['Train passengers'] += row['Number of passengers']\n",
    "processed_roadway_data = pd.read_excel('covid_processed.xlsx',sheet_name='Roadways')\n",
    "nrows = processed_roadway_data.shape[0]\n",
    "myrows = nrows\n",
    "for i in range(myrows):\n",
    "    row = processed_roadway_data.loc[i]\n",
    "    key = row['Arrival Date']\n",
    "    try:\n",
    "        key = key.date()\n",
    "    except:\n",
    "        print(\"road\",i, key)\n",
    "    if key in mydict:        \n",
    "        nrow = mydict[key]\n",
    "        nrow['Road passengers'] += row['Number of passengers']\n",
    "processed_airway_data = pd.read_excel('covid_processed.xlsx',sheet_name='Airways')\n",
    "nrows = processed_airway_data.shape[0]\n",
    "myrows = nrows\n",
    "for i in range(myrows):\n",
    "    row = processed_airway_data.loc[i]\n",
    "    key = row['Arrival Date']\n",
    "    try:\n",
    "        key = key.date()\n",
    "    except:\n",
    "        print(\"air\",i, key)\n",
    "    if key in mydict:        \n",
    "        nrow = mydict[key]\n",
    "        nrow['Air passengers'] += row['Number of passengers']\n",
    "print(len(row_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tmc_data = pd.read_excel('covid_processed.xlsx',sheet_name='TMC_district')\n",
    "nrows = processed_tmc_data.shape[0]\n",
    "myrows = nrows\n",
    "for i in range(myrows):\n",
    "    row = processed_tmc_data.loc[i]\n",
    "    key = row['Date']\n",
    "    try:\n",
    "        key = key.date()\n",
    "    except:\n",
    "        print(\"tmc\",i, key)\n",
    "    if key in mydict:        \n",
    "        nrow = mydict[key]\n",
    "        nrow['Total_TMC_capacity'] += row['Total capacity']\n",
    "        nrow['Total_TMC_occupants'] += row['Total occupancy ']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "writeDFToExcel(row_list, 'covid_processed_odisha.xlsx', 'Odisha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/District</th>\n",
       "      <th>Total Testing</th>\n",
       "      <th>Total Negative</th>\n",
       "      <th>Total Positive</th>\n",
       "      <th>Balasore</th>\n",
       "      <th>Bhadrak</th>\n",
       "      <th>Cuttack</th>\n",
       "      <th>Dhenkaname</th>\n",
       "      <th>Jajpur</th>\n",
       "      <th>Kalahandi</th>\n",
       "      <th>...</th>\n",
       "      <th>Malkangiri</th>\n",
       "      <th>Sambalpur</th>\n",
       "      <th>Nuapada</th>\n",
       "      <th>Bargarh</th>\n",
       "      <th>Gajapati</th>\n",
       "      <th>Nawarangpur</th>\n",
       "      <th>Sonepur</th>\n",
       "      <th>Rayagada</th>\n",
       "      <th>Sundargarh</th>\n",
       "      <th>Others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-10 00:00:00</td>\n",
       "      <td>23035.0</td>\n",
       "      <td>21694.0</td>\n",
       "      <td>1341.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-09 00:00:00</td>\n",
       "      <td>19083.0</td>\n",
       "      <td>17555.0</td>\n",
       "      <td>1528.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-08 00:00:00</td>\n",
       "      <td>16093.0</td>\n",
       "      <td>14359.0</td>\n",
       "      <td>1734.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-07 00:00:00</td>\n",
       "      <td>17444.0</td>\n",
       "      <td>15801.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-06 00:00:00</td>\n",
       "      <td>16055.0</td>\n",
       "      <td>14222.0</td>\n",
       "      <td>1833.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date/District  Total Testing  Total Negative  Total Positive  \\\n",
       "0  2020-08-10 00:00:00        23035.0         21694.0          1341.0   \n",
       "1  2020-08-09 00:00:00        19083.0         17555.0          1528.0   \n",
       "2  2020-08-08 00:00:00        16093.0         14359.0          1734.0   \n",
       "3  2020-08-07 00:00:00        17444.0         15801.0          1643.0   \n",
       "4  2020-08-06 00:00:00        16055.0         14222.0          1833.0   \n",
       "\n",
       "   Balasore  Bhadrak  Cuttack  Dhenkaname  Jajpur  Kalahandi  ...  Malkangiri  \\\n",
       "0      54.0     83.0     76.0        14.0    15.0       25.0  ...        17.0   \n",
       "1      43.0     70.0     72.0       107.0    33.0       31.0  ...        38.0   \n",
       "2      73.0     58.0    177.0        29.0    38.0       24.0  ...        52.0   \n",
       "3      73.0      2.0     98.0        36.0    36.0       30.0  ...        27.0   \n",
       "4      69.0     50.0    124.0        43.0    60.0       84.0  ...        36.0   \n",
       "\n",
       "   Sambalpur  Nuapada  Bargarh  Gajapati  Nawarangpur  Sonepur  Rayagada  \\\n",
       "0       26.0      7.0     56.0      20.0          6.0     14.0      75.0   \n",
       "1      168.0      2.0     10.0      31.0         23.0      5.0      27.0   \n",
       "2       14.0     22.0     51.0      85.0         13.0     13.0      18.0   \n",
       "3      112.0      1.0      7.0      35.0          5.0      0.0     136.0   \n",
       "4       39.0      1.0      8.0      35.0         11.0     33.0     152.0   \n",
       "\n",
       "   Sundargarh  Others  \n",
       "0        91.0     NaN  \n",
       "1       126.0     NaN  \n",
       "2       126.0     NaN  \n",
       "3       118.0     NaN  \n",
       "4       110.0     NaN  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6678\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "processed_roadway_data = pd.read_excel('covid_processed_roadways.xlsx',sheet_name='Roadways')\n",
    "nrows = processed_roadway_data.shape[0]\n",
    "myrows = nrows\n",
    "nrow_list = []\n",
    "for i in range(myrows):\n",
    "    row = processed_roadway_data.loc[i]\n",
    "    key = row['Arrival Date']\n",
    "#     print(i, key, type(key), isinstance(key, str))\n",
    "    if pd.isna(key):\n",
    "        key = row['Departure Date']        \n",
    "#         print(i, key, type(key), isinstance(key, str))\n",
    "        key = datetime.strptime(key,'%d-%b-%Y')\n",
    "        key = key.date()\n",
    "        \n",
    "    elif isinstance(key, str):\n",
    "        key = key[:10]\n",
    "        key = datetime.strptime(key,'%Y-%m-%d')\n",
    "        key = key.date()\n",
    "    nrow = dict()\n",
    "    nrow['Arrival Date'] = key\n",
    "    nrow['Destination District'] = row['Destination District']\n",
    "    nrow['Vehicle No'] = row['Vehicle No']\n",
    "    departureDate = row['Departure Date']\n",
    "    if isinstance(departureDate,str):\n",
    "        departureDate = datetime.strptime(departureDate,'%d-%b-%Y')\n",
    "        departureDate = departureDate.date()\n",
    "    nrow['Departure Date'] = departureDate\n",
    "    nrow['Origin District'] = row['Origin District']\n",
    "    nrow['Number of passengers'] = row['Number of passengers']\n",
    "    nrow['Age group (0-14)'] = row['Age group (0-14)']\n",
    "    nrow['Age group (15-40)'] = row['Age group (15-40)']\n",
    "    nrow['Age group (41-60)'] = row['Age group (41-60)']\n",
    "    nrow['Age group (60+)'] = row['Age group (60+)']\n",
    "    nrow['Number of males'] = row['Number of males']\n",
    "    nrow['Number of females'] = row['Number of females']\n",
    "    nrow['N_TMC_quarantined'] = row['N_TMC_quarantined']\n",
    "    nrow['N_Other_quarantined'] = row['N_Other_quarantined']\n",
    "    nrow['N_buses'] = row['N_buses']\n",
    "    nrow['N_private_vehicle'] = row['N_private_vehicle']\n",
    "    nrow_list.append(nrow)\n",
    "print(len(nrow_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6678\n"
     ]
    }
   ],
   "source": [
    "writeDFToExcel(nrow_list, 'covid_processed_roadways_new.xlsx', 'Roadways')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-15 01:46:13.057 <class 'str'>\n",
      "2020-05-15 <class 'str'>\n",
      "2020-05-15 00:00:00 <class 'datetime.datetime'>\n",
      "2020-05-15 <class 'datetime.date'>\n"
     ]
    }
   ],
   "source": [
    "key = processed_roadway_data.loc[0]['Arrival Date']\n",
    "print(key,type(key))\n",
    "key = key[:10]\n",
    "print(key,type(key))\n",
    "key = datetime.strptime(key,'%Y-%m-%d')\n",
    "print(key,type(key))\n",
    "key = key.date()\n",
    "print(key,type(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data '26-Apr-20' does not match format '%d-%m-%y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-251-1c31da4eb86b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdate_time_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistricts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_time_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'%d-%m-%y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/_strptime.py\u001b[0m in \u001b[0;36m_strptime_datetime\u001b[0;34m(cls, data_string, format)\u001b[0m\n\u001b[1;32m    566\u001b[0m     \"\"\"Return a class cls instance based on the input string and the\n\u001b[1;32m    567\u001b[0m     format string.\"\"\"\n\u001b[0;32m--> 568\u001b[0;31m     \u001b[0mtt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmtoff_fraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_strptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m     \u001b[0mtzname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmtoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfraction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/_strptime.py\u001b[0m in \u001b[0;36m_strptime\u001b[0;34m(data_string, format)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_regex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         raise ValueError(\"time data %r does not match format %r\" %\n\u001b[0m\u001b[1;32m    350\u001b[0m                          (data_string, format))\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data '26-Apr-20' does not match format '%d-%m-%y'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "date_time_str = districts.loc[1]['Date']\n",
    "date = datetime.strptime(date_time_str,'%d-%m-%y')\n",
    "\n",
    "print(date, type(date))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "someOdishaDistricts = ['Ganjam','Cuttack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xlrd\n",
    "# xlsx = xlrd.open_workbook(r'../data/Districts_new.xlsx', on_demand=True)\n",
    "# print(xlsx.sheet_names())\n",
    "\n",
    "districts = pd.read_excel('../data/Districts_new.xlsx',sheet_name=\"Sheet1\", skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-26 00:00:00 <class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "2020-04-26 <class 'datetime.date'>\n"
     ]
    }
   ],
   "source": [
    "districts.head()\n",
    "ndate = districts.loc[0]['Date']\n",
    "print(ndate,type(ndate))\n",
    "ndate = ndate.date()\n",
    "print(ndate,type(ndate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "odisha_daily = pd.read_excel('covid_processed.xlsx',sheet_name=\"Odisha\", skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "od = odisha_daily\n",
    "dates = od['Date']\n",
    "n_daily_influx = od['Train passengers'] + od['Road passengers'] + od['Air passengers']\n",
    "len(n_daily_influx)\n",
    "n_daily_cases = od['Positive cases']\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Daily Influx', color=color)\n",
    "ax1.plot(dates, n_daily_influx, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.set_xticklabels(dates, rotation = 45, ha=\"right\")\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Daily cases', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(dates, n_daily_cases, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_railway_data = pd.read_excel('covid_processed.xlsx',sheet_name='Railways')\n",
    "processed_airway_data = pd.read_excel('covid_processed.xlsx',sheet_name='Airways')\n",
    "processed_roadway_data = pd.read_excel('covid_processed.xlsx',sheet_name='Roadways')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n",
      "4850\n",
      "111\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "# imp_districts = ['Ganjam', 'Khordha', 'Cuttack', 'Sundargarh', 'Rayagada']\n",
    "nrows = districts.shape[0]\n",
    "imp_district = 'Rayagada'\n",
    "mydict = dict()\n",
    "row_list = []\n",
    "myrows = nrows\n",
    "for i in range(myrows):\n",
    "    row = districts.loc[i]\n",
    "    if row['State'] != 'Odisha' and row['District'].lower() != imp_district.lower():\n",
    "        continue\n",
    "    \n",
    "    key = row['Date']\n",
    "    key = key.date()\n",
    "    if key in mydict:\n",
    "        nrow = mydict[key]\n",
    "    else:                \n",
    "        nrow = dict()\n",
    "        nrow['Date'] = key\n",
    "        nrow['Positive cases'] = 0\n",
    "        nrow['Recovered'] = 0\n",
    "        nrow['Deceased'] = 0\n",
    "#         nrow['Total Tested'] = 0\n",
    "#         nrow['Negative cases'] = 0\n",
    "        nrow['Train passengers'] = 0\n",
    "        nrow['Road passengers'] = 0\n",
    "        nrow['Air passengers'] = 0\n",
    "        nrow['Total_TMC_capacity'] = 0\n",
    "        nrow['Total_TMC_occupants'] = 0\n",
    "        mydict[key] = nrow\n",
    "        row_list.append(nrow)\n",
    "    \n",
    "#     nrow['Positive cases'] += row['Confirmed']\n",
    "    nrow['Recovered'] += row['Recovered']\n",
    "    nrow['Deceased'] += row['Deceased']\n",
    "\n",
    "nrows = test_data.shape[0]\n",
    "myrows = nrows\n",
    "for i in range(myrows-3):\n",
    "    row = test_data.loc[i]\n",
    "    key = row['Date/District']\n",
    "    try:\n",
    "        key = key.date()\n",
    "    except:\n",
    "        print(i, key)\n",
    "    if key in mydict:        \n",
    "        nrow = mydict[key]\n",
    "        nrow['Positive cases'] = row[imp_district]\n",
    "        \n",
    "    \n",
    "print(len(row_list))\n",
    "\n",
    "nrows = processed_railway_data.shape[0]\n",
    "print(nrows)\n",
    "myrows = nrows\n",
    "for i in range(myrows):\n",
    "    row = processed_railway_data.loc[i]\n",
    "#     print(row['Destination District'], imp_district)\n",
    "    if row['Destination District'].lower() != imp_district.lower():\n",
    "        continue\n",
    "    key = row['Arrival Date']\n",
    "    try:\n",
    "        key = key.date()\n",
    "    except:\n",
    "        print(\"rail\",i, key)\n",
    "    if key in mydict:        \n",
    "        nrow = mydict[key]\n",
    "        nrow['Train passengers'] += row['Number of passengers']\n",
    "#         print(nrow['Train passengers'])\n",
    "    else:\n",
    "        print(i, key)\n",
    "\n",
    "nrows = processed_roadway_data.shape[0]\n",
    "myrows = nrows\n",
    "for i in range(myrows):\n",
    "    row = processed_roadway_data.loc[i]\n",
    "    if row['Destination District'].lower() != imp_district.lower():\n",
    "        continue\n",
    "    key = row['Arrival Date']\n",
    "    try:\n",
    "        key = key.date()\n",
    "    except:\n",
    "        print(\"road\",i, key)\n",
    "    if key in mydict:        \n",
    "        nrow = mydict[key]\n",
    "        nrow['Road passengers'] += row['Number of passengers']\n",
    "\n",
    "nrows = processed_airway_data.shape[0]\n",
    "myrows = nrows\n",
    "for i in range(myrows):\n",
    "    row = processed_airway_data.loc[i]\n",
    "    if row['Destination District'].lower() != imp_district.lower():\n",
    "        continue\n",
    "    \n",
    "    key = row['Arrival Date']\n",
    "    try:\n",
    "        key = key.date()\n",
    "    except:\n",
    "        print(\"air\",i, key)\n",
    "    if key in mydict:        \n",
    "        nrow = mydict[key]\n",
    "        nrow['Air passengers'] += row['Number of passengers']\n",
    "print(len(row_list))\n",
    "\n",
    "processed_tmc_data = pd.read_excel('covid_processed.xlsx',sheet_name='TMC_district')\n",
    "nrows = processed_tmc_data.shape[0]\n",
    "myrows = nrows\n",
    "for i in range(myrows):\n",
    "    row = processed_tmc_data.loc[i]\n",
    "    if row['District'].lower() != imp_district.lower():\n",
    "        continue\n",
    "\n",
    "    key = row['Date']\n",
    "    try:\n",
    "        key = key.date()\n",
    "    except:\n",
    "        print(\"tmc\",i, key)\n",
    "    if key in mydict:        \n",
    "        nrow = mydict[key]\n",
    "        nrow['Total_TMC_capacity'] += row['Total capacity']\n",
    "        nrow['Total_TMC_occupants'] += row['Total occupancy ']\n",
    "\n",
    "writeDFToExcel(row_list, 'covid_processed_'+imp_district+'.xlsx', imp_district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "writeDFToExcel(row_list, 'covid_processed_'+imp_district+'.xlsx', imp_district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_list[50]['Train passengers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "railway_data = pd.read_excel('../COVID_complete_data.xlsx', sheet_name=\"RAILWAY\", skiprows=1)\n",
    "road_data = pd.read_excel('../COVID_complete_data.xlsx', sheet_name=\"ROADWAYS\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Origin State\n",
      "0                ANDHRA PRADESH\n",
      "1                     JHARKHAND\n",
      "2                    TAMIL NADU\n",
      "3                   MAHARASHTRA\n",
      "4                  CHHATTISGARH\n",
      "5                   WEST BENGAL\n",
      "6                     KARNATAKA\n",
      "7                       GUJARAT\n",
      "8                MADHYA PRADESH\n",
      "9                     TELANGANA\n",
      "10                UTTAR PRADESH\n",
      "11                        BIHAR\n",
      "12                    RAJASTHAN\n",
      "13                       PUNJAB\n",
      "14                        ASSAM\n",
      "15                        DELHI\n",
      "16                      HARYANA\n",
      "17                  UTTARAKHAND\n",
      "18                          GOA\n",
      "19                       KERALA\n",
      "20            JAMMU AND KASHMIR\n",
      "21                       SIKKIM\n",
      "22             HIMACHAL PRADESH\n",
      "23                   PUDUCHERRY\n",
      "24                     NAGALAND\n",
      "25                   CHANDIGARH\n",
      "26                DAMAN AND DIU\n",
      "27                    MEGHALAYA\n",
      "28                      TRIPURA\n",
      "29       DADRA AND NAGAR HAVELI\n",
      "30            ARUNACHAL PRADESH\n",
      "31                      MANIPUR\n",
      "32  ANDAMAN AND NICOBAR ISLANDS\n",
      "33                      MIZORAM\n",
      "34                         None\n",
      "35                        NEPAL\n",
      "36                       LADAKH\n",
      "{'NAGALAND', 'PUNJAB', 'TELANGANA', 'ANDHRA PRADESH', 'JHARKHAND', 'SIKKIM', 'GUJARAT', 'WEST BENGAL', 'DADRA AND NAGAR HAVELI', 'GOA', 'LAKSHADWEEP', 'MEGHALAYA', 'UTTARAKHAND', 'BIHAR', 'NEPAL', 'HIMACHAL PRADESH', 'LADAKH', 'RAJASTHAN', 'MAHARASHTRA', 'JAMMU AND KASHMIR', None, 'PUDUCHERRY', 'HARYANA', 'ASSAM', 'MANIPUR', 'MIZORAM', 'KERALA', 'CHHATTISGARH', 'DELHI', 'KARNATAKA', 'ARUNACHAL PRADESH', 'TRIPURA', 'MADHYA PRADESH', 'CHANDIGARH', 'TAMIL NADU', 'ANDAMAN AND NICOBAR ISLANDS', 'UTTAR PRADESH', 'DAMAN AND DIU'}\n"
     ]
    }
   ],
   "source": [
    "# import pandasql\n",
    "# print(type(railway_data))\n",
    "# origin_state = 'Origin State'\n",
    "stateList = pandasql.sqldf('SELECT DISTINCT \"ORIGIN STATE\" FROM railway_data')\n",
    "\n",
    "stateList2 = pandasql.sqldf('SELECT DISTINCT \"ORIGIN STATE\" FROM road_data')\n",
    "print(stateList2)\n",
    "states = set([])\n",
    "for i in range(stateList.shape[0]):\n",
    "    row = stateList.loc[i]\n",
    "    if row['Origin State'] != 'None':\n",
    "        states.add(row['Origin State'])\n",
    "for i in range(stateList2.shape[0]):\n",
    "    row = stateList2.loc[i]\n",
    "    if row['Origin State'] != 'None':\n",
    "        states.add(row['Origin State'])\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NUAPADA', 'JAGATSINGHAPUR', 'NAYAGARH', 'SONEPUR', 'GANJAM', 'SAMBALPUR', 'CUTTACK', 'NABARANGPUR', 'KHORDHA', 'KENDRAPARA', 'GAJAPATI', 'JHARSUGUDA', 'BALESHWAR', 'KALAHANDI', 'RAYAGADA', 'DEOGARH', 'BOUDH', 'BARGARH', 'SUNDARGARH', 'KENDUJHAR', 'MALKANGIRI', 'PURI', 'BALANGIR', 'KANDHAMAL', 'MAYURBHANJ', 'KORAPUT', 'ANUGUL', 'DHENKANAL', 'BHADRAK', 'JAJAPUR'}\n"
     ]
    }
   ],
   "source": [
    "odishaDistrictList = pandasql.sqldf('SELECT DISTINCT \"Destination District\" FROM railway_data')\n",
    "\n",
    "odishaDistrictList2 = pandasql.sqldf('SELECT DISTINCT \"Destination District\" FROM road_data')\n",
    "\n",
    "odisha_districts = set([])\n",
    "for i in range(odishaDistrictList.shape[0]):\n",
    "    row = odishaDistrictList.loc[i]\n",
    "    if row['Destination District'] != 'None':\n",
    "        odisha_districts.add(row['Destination District'])\n",
    "for i in range(odishaDistrictList2.shape[0]):\n",
    "    row = odishaDistrictList2.loc[i]\n",
    "    if row['Destination District'] != 'None':\n",
    "        odisha_districts.add(row['Destination District'])\n",
    "print(odisha_districts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173 2020-03-06 2020-08-25\n"
     ]
    }
   ],
   "source": [
    "states = set([])\n",
    "odisha_districts = set([])\n",
    "from datetime import timedelta, date\n",
    "def daterange(date1, date2):\n",
    "    for n in range(int ((date2 - date1).days)+1):\n",
    "        yield date1 + timedelta(n)\n",
    "start_dt = date(2020, 3, 6)\n",
    "end_dt = date(2020, 8, 25)\n",
    "dates = []\n",
    "for dt in daterange(start_dt, end_dt):\n",
    "    dates.append(dt)\n",
    "print(len(dates), dates[0], dates[len(dates)-1])\n",
    "# mydict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAGALAND\n",
      "PUNJAB\n",
      "TELANGANA\n",
      "ANDHRA PRADESH\n",
      "JHARKHAND\n",
      "SIKKIM\n",
      "GUJARAT\n",
      "WEST BENGAL\n",
      "DADRA AND NAGAR HAVELI\n",
      "GOA\n",
      "LAKSHADWEEP\n",
      "MEGHALAYA\n",
      "UTTARAKHAND\n",
      "BIHAR\n",
      "NEPAL\n",
      "HIMACHAL PRADESH\n",
      "LADAKH\n",
      "RAJASTHAN\n",
      "MAHARASHTRA\n",
      "JAMMU AND KASHMIR\n",
      "None\n",
      "PUDUCHERRY\n",
      "HARYANA\n",
      "ASSAM\n",
      "MANIPUR\n",
      "MIZORAM\n",
      "KERALA\n",
      "CHHATTISGARH\n",
      "DELHI\n",
      "KARNATAKA\n",
      "ARUNACHAL PRADESH\n",
      "TRIPURA\n",
      "MADHYA PRADESH\n",
      "CHANDIGARH\n",
      "TAMIL NADU\n",
      "ANDAMAN AND NICOBAR ISLANDS\n",
      "UTTAR PRADESH\n",
      "DAMAN AND DIU\n"
     ]
    }
   ],
   "source": [
    "mydict = dict()\n",
    "arrival_date = 'Journey start date'\n",
    "nrows = road_data.shape[0]\n",
    "\n",
    "mydict = dict()\n",
    "myrows = 2\n",
    "row_list = []\n",
    "for state in states:\n",
    "    print(state)\n",
    "    if state == 'NEPAL' or state == 'None':\n",
    "        continue\n",
    "    for odistrict in odisha_districts:\n",
    "        for mydate in dates:\n",
    "            key = (mydate, odistrict, state)\n",
    "            nrow = dict()\n",
    "            nrow['Arrival Date'] = mydate\n",
    "            nrow['Destination District'] = odistrict\n",
    "            nrow['Origin State'] = state\n",
    "            nrow['Number of passengers'] = 0\n",
    "            nrow['Train passengers'] = 0\n",
    "            nrow['Age group (0-14)'] = 0\n",
    "            nrow['Age group (15-40)'] = 0\n",
    "            nrow['Age group (41-60)'] = 0\n",
    "            nrow['Age group (60+)'] = 0\n",
    "            nrow['Number of males'] = 0\n",
    "            nrow['Number of females'] = 0\n",
    "            nrow['N_TMC_quarantined'] = 0\n",
    "            nrow['N_Other_quarantined'] = 0\n",
    "            nrow['N_buses'] = 0\n",
    "            nrow['N_4-Wheeler'] = 0\n",
    "            nrow['N_2-Wheeler'] = 0\n",
    "\n",
    "            mydict[key] = nrow\n",
    "            row_list.append(nrow)\n",
    "            \n",
    "# writeDFToExcel(row_list, 'check.xlsx', 'econometrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87316 292932 192030\n"
     ]
    }
   ],
   "source": [
    "print(len(road_data), len(railway_data), len(row_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_type = 'Vehicle Type'\n",
    "vehicle_id = 'Vehicle No'\n",
    "arrival_date = 'Journey start date'\n",
    "nrows = road_data.shape[0]\n",
    "\n",
    "# mydict = dict()\n",
    "myrows = 2\n",
    "# row_list = []\n",
    "for i in range(nrows):\n",
    "    row = road_data.loc[i]\n",
    "    mydate = row[arrival_date]\n",
    "    try:\n",
    "#         mydate = convertStrDateToDate(mydate)\n",
    "        mydate = mydate.date()\n",
    "    except:\n",
    "        mydate = row['Journey start date']\n",
    "        mydate = convertJourneyStartDateToDate(mydate)\n",
    "#     print(mydate,type(mydate))\n",
    "    \n",
    "    key = (mydate, row[destination_district], row['Origin State'])\n",
    "    \n",
    "    if key in mydict:\n",
    "#         print(i, mydate)\n",
    "        nrow = mydict[key]        \n",
    "\n",
    "        nrow['Number of passengers'] += 1\n",
    "        if row[age] <= 14:\n",
    "            nrow['Age group (0-14)'] += 1\n",
    "        elif row[age] <= 40:\n",
    "            nrow['Age group (15-40)'] += 1\n",
    "        elif row[age] <= 40:\n",
    "            nrow['Age group (41-60)'] += 1\n",
    "        else:\n",
    "            nrow['Age group (60+)'] += 1\n",
    "        if row[gender] == 'Male':\n",
    "            nrow['Number of males'] += 1\n",
    "        else: \n",
    "            nrow['Number of females'] += 1\n",
    "        if row['TMC/Home'] == 'TMC':\n",
    "            nrow['N_TMC_quarantined'] += 1\n",
    "        else:\n",
    "            nrow['N_Other_quarantined'] += 1\n",
    "\n",
    "        if row['Vehicle Type'] == 'Bus':\n",
    "            nrow['N_buses'] += 1\n",
    "        elif row['Vehicle Type'] == '4-Wheeler':\n",
    "            nrow['N_4-Wheeler'] += 1\n",
    "        elif row['Vehicle Type'] == '2-Wheeler':\n",
    "            nrow['N_2-Wheeler'] += 1\n",
    "        \n",
    "    \n",
    "arrival_date = 'Travel Date'\n",
    "nrows = railway_data.shape[0]\n",
    "for i in range(nrows):\n",
    "    row = railway_data.loc[i]\n",
    "    mydate = row[arrival_date]\n",
    "    mydate = mydate.date()\n",
    "    key = (mydate, row[destination_district], row['Origin State'])\n",
    "    \n",
    "    if key in mydict:\n",
    "        nrow = mydict[key]\n",
    "        nrow['Number of passengers'] += 1\n",
    "        nrow['Train passengers'] += 1\n",
    "        if row[age] <= 14:\n",
    "            nrow['Age group (0-14)'] += 1\n",
    "        elif row[age] <= 40:\n",
    "            nrow['Age group (15-40)'] += 1\n",
    "        elif row[age] <= 40:\n",
    "            nrow['Age group (41-60)'] += 1\n",
    "        else:\n",
    "            nrow['Age group (60+)'] += 1\n",
    "        if row[gender] == 'Male':\n",
    "            nrow['Number of males'] += 1\n",
    "        else: \n",
    "            nrow['Number of females'] += 1\n",
    "        if row['TMC/home'] == 'TMC':\n",
    "            nrow['N_TMC_quarantined'] += 1\n",
    "        else:\n",
    "            nrow['N_Other_quarantined'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192030\n"
     ]
    }
   ],
   "source": [
    "writeDFToExcel(row_list, 'covid_processed_econometrics_new.xlsx', 'econometrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-15 01:46:13.057 <class 'str'> True\n",
      "2020-05-15 <class 'datetime.date'>\n",
      "2020-06-14 <class 'datetime.date'>\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "def convertStrDateToDate(key):\n",
    "#     key = nrow['Arrival Date']\n",
    "    key = key[:10]\n",
    "#     print(key,type(key))\n",
    "    key = datetime.strptime(key,'%Y-%m-%d')\n",
    "#     print(key,type(key))\n",
    "    key = key.date()\n",
    "#     print(key,type(key))\n",
    "    return key\n",
    "key = '2020-05-15 01:46:13.057'\n",
    "print(key,type(key), isinstance(key,str))\n",
    "key = convertStrDateToDate(key)\n",
    "print(key,type(key))\n",
    "\n",
    "def convertJourneyStartDateToDate(key):\n",
    "#     key = nrow['Arrival Date']\n",
    "#     key = key[:11]\n",
    "#     print(key,type(key))\n",
    "    key = datetime.strptime(key,'%d-%b-%Y')\n",
    "#     print(key,type(key))\n",
    "    key = key.date()\n",
    "#     print(key,type(key))\n",
    "    return key\n",
    "\n",
    "key = '14-Jun-2020'\n",
    "key = convertJourneyStartDateToDate(key)\n",
    "print(key,type(key))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2020, 5, 17)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "railway_data.loc[0]['Travel Date'].date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-15 01:46:13.057 <class 'str'>\n",
      "2020-05-15 <class 'datetime.date'>\n"
     ]
    }
   ],
   "source": [
    "key = road_data.loc[0]['Checkin Date']\n",
    "print(key, type(key))\n",
    "key = convertStrDateToDate(key)\n",
    "print(key, type(key))\n",
    "key = railway_data.loc[0]['Travel Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-9b7347eaf373>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-9b7347eaf373>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    influx =\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "influx = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "35\n",
      "1\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "mydict = dict()\n",
    "state_parameter_data = pd.read_excel('state_parameters_backup.xlsx', sheet_name=\"Influx\")\n",
    "nrows = state_parameter_data.shape[0]\n",
    "print(nrows)\n",
    "nrow_list = []\n",
    "for i in range(nrows):\n",
    "    staterow = state_parameter_data.loc[i]    \n",
    "    if staterow['State'] != 'NEPAL' and pd.notna(staterow['State']):\n",
    "#         print('created entry for ', staterow['Origin State'])\n",
    "        key = staterow['State']\n",
    "        nrow = dict()\n",
    "        nrow['State'] = key\n",
    "        nrow['Total Influx'] = staterow['Total Influx']\n",
    "        nrow['Infected'] = 0\n",
    "        nrow['Susceptible'] = 0\n",
    "        nrow['Confirmed'] = 0\n",
    "        nrow['Deceased'] = 0\n",
    "        nrow['Recovered'] = 0\n",
    "        nrow['Population'] = 0\n",
    "        nrow['Percentage Infected'] = 0\n",
    "        nrow['Percentage Susceptible'] = 0\n",
    "        nrow['Percentage Recovered'] = 0\n",
    "        nrow['Positive'] = 0\n",
    "        nrow['Negative'] = 0\n",
    "        nrow['Positivity rate'] = 0\n",
    "        nrow['Total Tested'] = 0\n",
    "        nrow['Population'] = 0\n",
    "        nrow['Area'] = 0\n",
    "        mydict[key] = nrow\n",
    "        nrow_list.append(nrow)\n",
    "\n",
    "nrows = len(nrow_list)\n",
    "print(nrows)\n",
    "\n",
    "import json\n",
    "data = 0\n",
    "with open ('../data/state_test_data.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    states_tested_data = data['states_tested_data']\n",
    "    print(len(data))\n",
    "    nrows = len(states_tested_data)\n",
    "    for i in range(nrows):\n",
    "        row = states_tested_data[i]\n",
    "        key = str.upper(row['state'])\n",
    "        if key in mydict:\n",
    "            nrow = mydict[key]        \n",
    "            if (row['positive'] != ''):\n",
    "                nrow['Positive'] = max(nrow['Positive'],int(row['positive']))\n",
    "            if (row['negative'] not in {'',' '}):\n",
    "                nrow['Negative'] = int(row['negative'])\n",
    "            if (row['testpositivityrate'] != ''):\n",
    "                nrow['Positivity rate'] = max(nrow['Positivity rate'],float(row['testpositivityrate'][:-1]))\n",
    "            if (row['totaltested'] != ''):\n",
    "                nrow['Total Tested'] = max(nrow['Total Tested'],int(row['totaltested']))\n",
    "            if (row['populationncp2019projection'] != ''):\n",
    "                nrow['Population'] = max(nrow['Population'],int(row['populationncp2019projection']))\n",
    "        \n",
    "print(len(nrow_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197220"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AB'"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str.upper('abc'[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "35\n",
      "1\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "mydict = dict()\n",
    "state_parameter_data = pd.read_excel('state_parameters_backup.xlsx', sheet_name=\"Influx\")\n",
    "nrows = state_parameter_data.shape[0]\n",
    "print(nrows)\n",
    "nrow_list = []\n",
    "for i in range(nrows):\n",
    "    staterow = state_parameter_data.loc[i]    \n",
    "    if staterow['State'] != 'NEPAL' and pd.notna(staterow['State']):\n",
    "#         print('created entry for ', staterow['Origin State'])\n",
    "        key = staterow['State']\n",
    "        nrow = dict()\n",
    "        nrow['State'] = key\n",
    "        nrow['Total Influx'] = staterow['Total Influx']\n",
    "        nrow['Infected'] = 0\n",
    "        nrow['Susceptible'] = 0\n",
    "        nrow['Confirmed'] = 0\n",
    "        nrow['Deceased'] = 0\n",
    "        nrow['Recovered'] = 0\n",
    "        nrow['Population'] = 0\n",
    "        nrow['Percentage Infected'] = 0\n",
    "        nrow['Percentage Susceptible'] = 0\n",
    "        nrow['Percentage Recovered'] = 0\n",
    "        nrow['Positive'] = 0\n",
    "        nrow['Negative'] = 0\n",
    "        nrow['Positivity rate'] = 0\n",
    "        nrow['Total Tested'] = 0\n",
    "        nrow['Population'] = 0\n",
    "        nrow['Area'] = 0\n",
    "        mydict[key] = nrow\n",
    "        nrow_list.append(nrow)\n",
    "\n",
    "nrows = len(nrow_list)\n",
    "print(nrows)\n",
    "\n",
    "import json, math\n",
    "data = 0\n",
    "daman_diu_pop = 52076\n",
    "dadra_nagar_pop = 343709\n",
    "with open ('../data/state_test_data.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    states_tested_data = data['states_tested_data']\n",
    "    print(len(data))\n",
    "    nrows = len(states_tested_data)\n",
    "    for i in range(nrows):\n",
    "        row = states_tested_data[i]\n",
    "        key = str.upper(row['state'])\n",
    "        if key in mydict:\n",
    "            nrow = mydict[key]        \n",
    "            if (row['positive'] != ''):\n",
    "                nrow['Positive'] = max(nrow['Positive'],int(row['positive']))\n",
    "            if (row['negative'] not in {'',' '}):\n",
    "                nrow['Negative'] = int(row['negative'])\n",
    "            if (row['testpositivityrate'] != ''):\n",
    "                nrow['Positivity rate'] = max(nrow['Positivity rate'],float(row['testpositivityrate'][:-1]))\n",
    "            if (row['totaltested'] != ''):\n",
    "                nrow['Total Tested'] = max(nrow['Total Tested'],int(row['totaltested']))\n",
    "            if (row['populationncp2019projection'] != ''):\n",
    "                nrow['Population'] = max(nrow['Population'],int(row['populationncp2019projection']))\n",
    "        elif key == str.upper('Dadra and Nagar Haveli and Daman and Diu'):\n",
    "            territories = ['DADRA AND NAGAR HAVELI', 'DAMAN AND DIU']\n",
    "            n_pops = [dadra_nagar_pop, daman_diu_pop]\n",
    "            n_total_pop = sum(n_pops)\n",
    "            for i in range(2):\n",
    "                nrow = mydict[territories[i]]\n",
    "                n_pop = n_pops[i]\n",
    "            \n",
    "                if (row['positive'] != ''):\n",
    "                    nrow['Positive'] = math.floor(max(nrow['Positive'],int(row['positive'])) * n_pop / n_total_pop)\n",
    "                if (row['negative'] not in {'',' '}):\n",
    "                    nrow['Negative'] = math.floor(int(row['negative']) * n_pop / n_total_pop)\n",
    "                if (row['testpositivityrate'] != ''):\n",
    "                    nrow['Positivity rate'] = math.floor(max(nrow['Positivity rate'],float(row['testpositivityrate'][:-1]))  * n_pop / n_total_pop)\n",
    "                if (row['totaltested'] != ''):\n",
    "                    nrow['Total Tested'] = math.floor(max(nrow['Total Tested'],int(row['totaltested']))  * n_pop / n_total_pop)\n",
    "                if (row['populationncp2019projection'] != ''):\n",
    "                    nrow['Population'] = n_pop \n",
    "            \n",
    "print(len(nrow_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "35 [{'State': 'ANDHRA PRADESH', 'Total Influx': 44892, 'Infected': 94209, 'Susceptible': 51827910, 'Confirmed': 393090, 'Deceased': 3633, 'Recovered': 295248, 'Population': 52221000, 'Percentage Infected': 0.0018040443499741483, 'Percentage Susceptible': 0.9924725685069224, 'Percentage Recovered': 0.005653817429769633, 'Positive': 235525, 'Negative': 3183165, 'Positivity rate': 7.33, 'Total Tested': 3418690, 'Area': 0}, {'State': 'JHARKHAND', 'Total Influx': 11100, 'Infected': 10458, 'Susceptible': 37369689, 'Confirmed': 33311, 'Deceased': 367, 'Recovered': 22486, 'Population': 37403000, 'Percentage Infected': 0.00027960324038178757, 'Percentage Susceptible': 0.999109402989065, 'Percentage Recovered': 0.0006011817233911718, 'Positive': 23224, 'Negative': 620366, 'Positivity rate': 3.51, 'Total Tested': 643590, 'Area': 0}, {'State': 'TAMIL NADU', 'Total Influx': 109250, 'Infected': 52364, 'Susceptible': 75291758, 'Confirmed': 403242, 'Deceased': 6948, 'Recovered': 343930, 'Population': 75695000, 'Percentage Infected': 0.0006917762071471035, 'Percentage Susceptible': 0.9946728053372086, 'Percentage Recovered': 0.004543629037585045, 'Positive': 367430, 'Negative': 4054931, 'Positivity rate': 13.01, 'Total Tested': 4422361, 'Area': 0}, {'State': 'MAHARASHTRA', 'Total Influx': 52130, 'Infected': 178561, 'Susceptible': 121419432, 'Confirmed': 733568, 'Deceased': 23444, 'Recovered': 531563, 'Population': 122153000, 'Percentage Infected': 0.0014617815362700875, 'Percentage Susceptible': 0.9939946788044501, 'Percentage Recovered': 0.004351616415478948, 'Positive': 607631, 'Negative': 3190675, 'Positivity rate': 20.27, 'Total Tested': 3798306, 'Area': 0}, {'State': 'CHHATTISGARH', 'Total Influx': 8366, 'Infected': 10806, 'Susceptible': 28698342, 'Confirmed': 25658, 'Deceased': 245, 'Recovered': 14607, 'Population': 28724000, 'Percentage Infected': 0.00037620108619969365, 'Percentage Susceptible': 0.9991067400083554, 'Percentage Recovered': 0.000508529452722462, 'Positive': 19459, 'Negative': 500219, 'Positivity rate': 2.78, 'Total Tested': 519678, 'Area': 0}, {'State': 'WEST BENGAL', 'Total Influx': 62390, 'Infected': 26709, 'Susceptible': 96755228, 'Confirmed': 150772, 'Deceased': 3017, 'Recovered': 121046, 'Population': 96906000, 'Percentage Infected': 0.00027561760881679155, 'Percentage Susceptible': 0.9984441417456091, 'Percentage Recovered': 0.0012491073824118218, 'Positive': 135596, 'Negative': 1538537, 'Positivity rate': 7.5, 'Total Tested': 1674133, 'Area': 0}, {'State': 'KARNATAKA', 'Total Influx': 68710, 'Infected': 85006, 'Susceptible': 65488208, 'Confirmed': 309792, 'Deceased': 5232, 'Recovered': 219554, 'Population': 65798000, 'Percentage Infected': 0.0012919237666798383, 'Percentage Susceptible': 0.9952917717863765, 'Percentage Recovered': 0.003336788352229551, 'Positive': 264546, 'Negative': 2316075, 'Positivity rate': 8.61, 'Total Tested': 2580621, 'Area': 0}, {'State': 'GUJARAT', 'Total Influx': 227582, 'Infected': 14766, 'Susceptible': 67844671, 'Confirmed': 91329, 'Deceased': 2962, 'Recovered': 73601, 'Population': 67936000, 'Percentage Infected': 0.00021735162505887894, 'Percentage Susceptible': 0.9986556612105512, 'Percentage Recovered': 0.001083387305699482, 'Positive': 90139, 'Negative': 1879585, 'Positivity rate': 9.15, 'Total Tested': 1969724, 'Area': 0}, {'State': 'MADHYA PRADESH', 'Total Influx': 2434, 'Infected': 12422, 'Susceptible': 82173819, 'Confirmed': 58181, 'Deceased': 1306, 'Recovered': 44453, 'Population': 82232000, 'Percentage Infected': 0.00015106041443720207, 'Percentage Susceptible': 0.9992924773810682, 'Percentage Recovered': 0.0005405803093686156, 'Positive': 50640, 'Negative': 1197381, 'Positivity rate': 9.77, 'Total Tested': 1248021, 'Area': 0}, {'State': 'TELANGANA', 'Total Influx': 81832, 'Infected': 27600, 'Susceptible': 37105517, 'Confirmed': 114483, 'Deceased': 788, 'Recovered': 86095, 'Population': 37220000, 'Percentage Infected': 0.0007415368081676518, 'Percentage Susceptible': 0.9969241536808168, 'Percentage Recovered': 0.0023131380977968836, 'Positive': 111688, 'Negative': 970406, 'Positivity rate': 21.99, 'Total Tested': 1082094, 'Area': 0}, {'State': 'UTTAR PRADESH', 'Total Influx': 5658, 'Infected': 52309, 'Susceptible': 224770581, 'Confirmed': 208419, 'Deceased': 3217, 'Recovered': 152893, 'Population': 224979000, 'Percentage Infected': 0.00023250614501797945, 'Percentage Susceptible': 0.9990736068699745, 'Percentage Recovered': 0.0006795878726458914, 'Positive': 126722, 'Negative': 4814957, 'Positivity rate': 5.29, 'Total Tested': 4941679, 'Area': 0}, {'State': 'BIHAR', 'Total Influx': 6106, 'Infected': 18492, 'Susceptible': 119391150, 'Confirmed': 128850, 'Deceased': 662, 'Recovered': 109696, 'Population': 119520000, 'Percentage Infected': 0.00015471887550200803, 'Percentage Susceptible': 0.998921937751004, 'Percentage Recovered': 0.0009178045515394913, 'Positive': 90553, 'Negative': 2582134, 'Positivity rate': 9.45, 'Total Tested': 2672687, 'Area': 0}, {'State': 'RAJASTHAN', 'Total Influx': 3862, 'Infected': 14646, 'Susceptible': 77188697, 'Confirmed': 75303, 'Deceased': 998, 'Recovered': 59659, 'Population': 77264000, 'Percentage Infected': 0.00018955787947815282, 'Percentage Susceptible': 0.9990253805135639, 'Percentage Recovered': 0.0007721448540070408, 'Positive': 67954, 'Negative': 2128399, 'Positivity rate': 2.88, 'Total Tested': 2196353, 'Area': 0}, {'State': 'PUNJAB', 'Total Influx': 504, 'Infected': 15608, 'Susceptible': 29811164, 'Confirmed': 47836, 'Deceased': 1256, 'Recovered': 30972, 'Population': 29859000, 'Percentage Infected': 0.0005227234669613851, 'Percentage Susceptible': 0.9983979369704277, 'Percentage Recovered': 0.0010372751934090224, 'Positive': 39327, 'Negative': 924724, 'Positivity rate': 4.8, 'Total Tested': 964051, 'Area': 0}, {'State': 'ASSAM', 'Total Influx': 490, 'Infected': 19222, 'Susceptible': 34194192, 'Confirmed': 98808, 'Deceased': 278, 'Recovered': 79308, 'Population': 34293000, 'Percentage Infected': 0.0005605225556235966, 'Percentage Susceptible': 0.9971187122736419, 'Percentage Recovered': 0.002312658560055988, 'Positive': 87908, 'Negative': 1983533, 'Positivity rate': 4.35, 'Total Tested': 2071441, 'Area': 0}, {'State': 'DELHI', 'Total Influx': 6774, 'Infected': 13208, 'Susceptible': 19646396, 'Confirmed': 167604, 'Deceased': 4369, 'Recovered': 150027, 'Population': 19814000, 'Percentage Infected': 0.0006665993741798728, 'Percentage Susceptible': 0.9915411325325527, 'Percentage Recovered': 0.007571767437165641, 'Positive': 151928, 'Negative': 1330733, 'Positivity rate': 16.84, 'Total Tested': 1482661, 'Area': 0}, {'State': 'HARYANA', 'Total Influx': 5382, 'Infected': 9962, 'Susceptible': 28612702, 'Confirmed': 59298, 'Deceased': 646, 'Recovered': 48690, 'Population': 28672000, 'Percentage Infected': 0.00034744698660714283, 'Percentage Susceptible': 0.9979318498883929, 'Percentage Recovered': 0.0016981724330357142, 'Positive': 58005, 'Negative': 967519, 'Positivity rate': 5.91, 'Total Tested': 1025524, 'Area': 0}, {'State': 'UTTARAKHAND', 'Total Influx': 194, 'Infected': 4806, 'Susceptible': 11124451, 'Confirmed': 16549, 'Deceased': 219, 'Recovered': 11524, 'Population': 11141000, 'Percentage Infected': 0.00043137958890584327, 'Percentage Susceptible': 0.9985145857642941, 'Percentage Recovered': 0.0010343775244592048, 'Positive': 14083, 'Negative': 320896, 'Positivity rate': 4.39, 'Total Tested': 334979, 'Area': 0}, {'State': 'GOA', 'Total Influx': 11718, 'Infected': 3445, 'Susceptible': 1524517, 'Confirmed': 15483, 'Deceased': 171, 'Recovered': 11867, 'Population': 1540000, 'Percentage Infected': 0.002237012987012987, 'Percentage Susceptible': 0.9899461038961039, 'Percentage Recovered': 0.007705844155844156, 'Positive': 12333, 'Negative': 174807, 'Positivity rate': 4.17, 'Total Tested': 187140, 'Area': 0}, {'State': 'KERALA', 'Total Influx': 44810, 'Infected': 22736, 'Susceptible': 35058239, 'Confirmed': 66761, 'Deceased': 268, 'Recovered': 43757, 'Population': 35125000, 'Percentage Infected': 0.000647288256227758, 'Percentage Susceptible': 0.9980993309608541, 'Percentage Recovered': 0.0012457508896797152, 'Positive': 64356, 'Negative': 1461436, 'Positivity rate': 3.38, 'Total Tested': 1525792, 'Area': 0}, {'State': 'JAMMU AND KASHMIR', 'Total Influx': 276, 'Infected': 7743, 'Susceptible': 13167865, 'Confirmed': 35135, 'Deceased': 671, 'Recovered': 26721, 'Population': 13203000, 'Percentage Infected': 0.0005864576232674393, 'Percentage Susceptible': 0.9973388623797622, 'Percentage Recovered': 0.002023858214042263, 'Positive': 31371, 'Negative': 871306, 'Positivity rate': 6.99, 'Total Tested': 902677, 'Area': 0}, {'State': 'SIKKIM', 'Total Influx': 226, 'Infected': 407, 'Susceptible': 662514, 'Confirmed': 1486, 'Deceased': 3, 'Recovered': 1076, 'Population': 664000, 'Percentage Infected': 0.0006129518072289157, 'Percentage Susceptible': 0.997762048192771, 'Percentage Recovered': 0.0016204819277108435, 'Positive': 910, 'Negative': 38041, 'Positivity rate': 2.52, 'Total Tested': 38951, 'Area': 0}, {'State': 'HIMACHAL PRADESH', 'Total Influx': 186, 'Infected': 1480, 'Susceptible': 7294679, 'Confirmed': 5321, 'Deceased': 31, 'Recovered': 3810, 'Population': 7300000, 'Percentage Infected': 0.00020273972602739726, 'Percentage Susceptible': 0.999271095890411, 'Percentage Recovered': 0.0005219178082191781, 'Positive': 3993, 'Negative': 199832, 'Positivity rate': 3.33, 'Total Tested': 203825, 'Area': 0}, {'State': 'PUDUCHERRY', 'Total Influx': 2174, 'Infected': 4483, 'Susceptible': 1491566, 'Confirmed': 12434, 'Deceased': 190, 'Recovered': 7761, 'Population': 1504000, 'Percentage Infected': 0.002980718085106383, 'Percentage Susceptible': 0.9917327127659574, 'Percentage Recovered': 0.005160239361702128, 'Positive': 10112, 'Negative': 58776, 'Positivity rate': 8.1, 'Total Tested': 68888, 'Area': 0}, {'State': 'NAGALAND', 'Total Influx': 24, 'Infected': 1041, 'Susceptible': 2146216, 'Confirmed': 3784, 'Deceased': 8, 'Recovered': 2735, 'Population': 2150000, 'Percentage Infected': 0.0004841860465116279, 'Percentage Susceptible': 0.99824, 'Percentage Recovered': 0.001272093023255814, 'Positive': 3520, 'Negative': 54533, 'Positivity rate': 4.09, 'Total Tested': 58053, 'Area': 0}, {'State': 'CHANDIGARH', 'Total Influx': 82, 'Infected': 1544, 'Susceptible': 1175436, 'Confirmed': 3564, 'Deceased': 43, 'Recovered': 1977, 'Population': 1179000, 'Percentage Infected': 0.0013095843935538591, 'Percentage Susceptible': 0.9969770992366412, 'Percentage Recovered': 0.0016768447837150126, 'Positive': 2305, 'Negative': 24771, 'Positivity rate': 14.52, 'Total Tested': 27076, 'Area': 0}, {'State': 'DAMAN AND DIU', 'Total Influx': 510, 'Infected': 156, 'Susceptible': 50874, 'Confirmed': 1202, 'Deceased': 1, 'Recovered': 1045, 'Population': 52076, 'Percentage Infected': 0.0029956217835471234, 'Percentage Susceptible': 0.9769183501036947, 'Percentage Recovered': 0.02006682540901759, 'Positive': 284, 'Negative': 6502, 'Positivity rate': 0, 'Total Tested': 6786, 'Area': 0}, {'State': 'MEGHALAYA', 'Total Influx': 68, 'Infected': 1222, 'Susceptible': 3221871, 'Confirmed': 2129, 'Deceased': 8, 'Recovered': 899, 'Population': 3224000, 'Percentage Infected': 0.0003790322580645161, 'Percentage Susceptible': 0.9993396401985112, 'Percentage Recovered': 0.0002788461538461538, 'Positive': 1718, 'Negative': 77408, 'Positivity rate': 2.31, 'Total Tested': 79126, 'Area': 0}, {'State': 'TRIPURA', 'Total Influx': 206, 'Infected': 3142, 'Susceptible': 3982076, 'Confirmed': 9924, 'Deceased': 85, 'Recovered': 6697, 'Population': 3992000, 'Percentage Infected': 0.0007870741482965932, 'Percentage Susceptible': 0.9975140280561122, 'Percentage Recovered': 0.0016776052104208418, 'Positive': 9539, 'Negative': 242118, 'Positivity rate': 2.88, 'Total Tested': 251657, 'Area': 0}, {'State': 'DADRA AND NAGAR HAVELI', 'Total Influx': 1634, 'Infected': 191, 'Susceptible': 342649, 'Confirmed': 1060, 'Deceased': 1, 'Recovered': 868, 'Population': 343709, 'Percentage Infected': 0.0005557026438062431, 'Percentage Susceptible': 0.9969159957987717, 'Percentage Recovered': 0.0025253921194964345, 'Positive': 1876, 'Negative': 42917, 'Positivity rate': 2, 'Total Tested': 44793, 'Area': 0}, {'State': 'ARUNACHAL PRADESH', 'Total Influx': 36, 'Infected': 987, 'Susceptible': 1500445, 'Confirmed': 3555, 'Deceased': 5, 'Recovered': 2563, 'Population': 1504000, 'Percentage Infected': 0.00065625, 'Percentage Susceptible': 0.9976363031914893, 'Percentage Recovered': 0.001704122340425532, 'Positive': 2658, 'Negative': 150194, 'Positivity rate': 2.11, 'Total Tested': 152852, 'Area': 0}, {'State': 'MANIPUR', 'Total Influx': 18, 'Infected': 1743, 'Susceptible': 3097275, 'Confirmed': 5725, 'Deceased': 25, 'Recovered': 3957, 'Population': 3103000, 'Percentage Infected': 0.0005617144698678698, 'Percentage Susceptible': 0.998155011279407, 'Percentage Recovered': 0.0012752175314212054, 'Positive': 4765, 'Negative': 135845, 'Positivity rate': 2.87, 'Total Tested': 140610, 'Area': 0}, {'State': 'ANDAMAN AND NICOBAR ISLANDS', 'Total Influx': 16, 'Infected': 635, 'Susceptible': 394015, 'Confirmed': 2985, 'Deceased': 41, 'Recovered': 2309, 'Population': 397000, 'Percentage Infected': 0.0015994962216624685, 'Percentage Susceptible': 0.9924811083123426, 'Percentage Recovered': 0.005816120906801008, 'Positive': 2945, 'Negative': 28137, 'Positivity rate': 1.5, 'Total Tested': 31082, 'Area': 0}, {'State': 'MIZORAM', 'Total Influx': 20, 'Infected': 474, 'Susceptible': 1191026, 'Confirmed': 974, 'Deceased': 0, 'Recovered': 500, 'Population': 1192000, 'Percentage Infected': 0.0003976510067114094, 'Percentage Susceptible': 0.9991828859060403, 'Percentage Recovered': 0.00041946308724832214, 'Positive': 713, 'Negative': 35527, 'Positivity rate': 3.71, 'Total Tested': 36240, 'Area': 0}, {'State': 'LADAKH', 'Total Influx': 6, 'Infected': 846, 'Susceptible': 290549, 'Confirmed': 2451, 'Deceased': 25, 'Recovered': 1580, 'Population': 293000, 'Percentage Infected': 0.002887372013651877, 'Percentage Susceptible': 0.9916348122866894, 'Percentage Recovered': 0.005392491467576792, 'Positive': 1909, 'Negative': 26810, 'Positivity rate': 7.29, 'Total Tested': 28719, 'Area': 0}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open ('../data/state_district_wise.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    states_district_data = data\n",
    "    print(len(data))\n",
    "    nrows = len(states_district_data)\n",
    "    for key in states_district_data:\n",
    "        if key == \"State Unassigned\":\n",
    "            continue\n",
    "        state_data = states_district_data[key]        \n",
    "        if key == 'Dadra and Nagar Haveli and Daman and Diu':\n",
    "            subkeys = ['Daman and Diu','Dadra and Nagar Haveli']\n",
    "            rows = state_data['districtData']            \n",
    "            nrow = mydict[str.upper('Daman and Diu')]\n",
    "            row = rows['Daman']\n",
    "            nrow['Confirmed'] += row['confirmed']\n",
    "            nrow['Recovered'] += row['recovered']\n",
    "            nrow['Deceased'] += row['deceased'] \n",
    "            row = rows['Diu']\n",
    "            nrow['Confirmed'] += row['confirmed']\n",
    "            nrow['Recovered'] += row['recovered']\n",
    "            nrow['Deceased'] += row['deceased'] \n",
    "            \n",
    "            nrow = mydict[str.upper('Dadra and Nagar Haveli')]\n",
    "            row = rows['Dadra and Nagar Haveli']\n",
    "            nrow['Confirmed'] += row['confirmed']\n",
    "            nrow['Recovered'] += row['recovered']\n",
    "            nrow['Deceased'] += row['deceased'] \n",
    "            \n",
    "            continue\n",
    "        \n",
    "        key = str.upper(key)\n",
    "        if key not in mydict:\n",
    "            continue\n",
    "        nrow = mydict[key]\n",
    "        rows = state_data['districtData']\n",
    "\n",
    "        for districtkey in rows:\n",
    "            row = rows[districtkey]\n",
    "#             print(row, nrow['Confirmed'])\n",
    "#             print(row['confirmed'])\n",
    "            nrow['Confirmed'] += row['confirmed']\n",
    "            nrow['Recovered'] += row['recovered']\n",
    "            nrow['Deceased'] += row['deceased'] \n",
    "            \n",
    "for key in mydict:\n",
    "    nrow = mydict[key]\n",
    "    nrow['Infected'] = nrow['Confirmed'] - nrow['Recovered'] - nrow['Deceased']\n",
    "    nrow['Susceptible'] = nrow['Population'] - nrow['Confirmed']\n",
    "    nrow['Negative'] = nrow['Total Tested'] - nrow['Positive']\n",
    "    \n",
    "    if nrow['Population'] != 0:\n",
    "        nrow['Percentage Infected'] = nrow['Infected'] / nrow['Population']\n",
    "        nrow['Percentage Susceptible'] = nrow['Susceptible'] / nrow['Population']\n",
    "        nrow['Percentage Recovered'] = nrow['Recovered'] / nrow['Population']\n",
    "\n",
    "print(len(nrow_list), nrow_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "writeDFToExcel(nrow_list, 'state_parameters.xlsx', 'Influx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "railway_processed_data = pd.read_excel('covid_processed.xlsx', sheet_name=\"Railways\", skiprows=0)\n",
    "road_processed_data = pd.read_excel('covid_processed.xlsx', sheet_name=\"Roadways\", skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14073\n"
     ]
    }
   ],
   "source": [
    "# import datetime\n",
    "mydict = dict()\n",
    "nrows = road_processed_data.shape[0]\n",
    "row_list = []\n",
    "for i in range(nrows):\n",
    "    row = road_processed_data.loc[i]\n",
    "    week = row['Arrival Date'].date().isocalendar()[1]\n",
    "    key = (week, row['Destination District'], row['Origin State'], row['Origin District'])\n",
    "    if key in mydict:\n",
    "        nrow = mydict[key]\n",
    "    else:\n",
    "        nrow = dict()\n",
    "        nrow['Week'] = week\n",
    "        nrow['Destination District'] = row['Destination District']\n",
    "        nrow['Origin State'] = row['Origin State']\n",
    "        nrow['Origin District'] = row['Origin District']\n",
    "        nrow['Train Passengers'] = 0\n",
    "        nrow['Road Passengers'] = 0\n",
    "#         nrow['Active Cases'] = 0\n",
    "        mydict[key] = nrow\n",
    "        row_list.append(nrow)\n",
    "    \n",
    "    nrow['Road Passengers'] += row['Number of passengers']\n",
    "\n",
    "nrows = railway_processed_data.shape[0]\n",
    "for i in range(nrows):\n",
    "    row = railway_processed_data.loc[i]\n",
    "    week = row['Arrival Date'].date().isocalendar()[1]\n",
    "    key = (week, row['Destination District'], row['Origin State'], row['Origin District'])\n",
    "    if key in mydict:\n",
    "        nrow = mydict[key]\n",
    "    else:\n",
    "        nrow = dict()\n",
    "        nrow['Week'] = week\n",
    "        nrow['Destination District'] = row['Destination District']\n",
    "        nrow['Origin State'] = row['Origin State']\n",
    "        nrow['Origin District'] = row['Origin District']\n",
    "        nrow['Train Passengers'] = 0\n",
    "        nrow['Road Passengers'] = 0\n",
    "#         nrow['Active Cases'] = 0\n",
    "        mydict[key] = nrow\n",
    "        row_list.append(nrow)\n",
    "    \n",
    "    nrow['Train Passengers'] += row['Number of passengers']\n",
    "\n",
    "writeDFToExcel(row_list, 'covid_processed_weekly_influx.xlsx', 'Weekly Influx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_influx_data = pd.read_excel('covid_processed_weekly_influx.xlsx', sheet_name=\"Weekly Influx\", skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Week</th>\n",
       "      <th>Destination District</th>\n",
       "      <th>Origin State</th>\n",
       "      <th>Origin District</th>\n",
       "      <th>Train Passengers</th>\n",
       "      <th>Road Passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>ANUGUL</td>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "      <td>EAST GODAVARI</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>ANUGUL</td>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "      <td>VIZIANAGARAM</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>ANUGUL</td>\n",
       "      <td>ANDHRA PRADESH</td>\n",
       "      <td>EAST GODAVARI</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>ANUGUL</td>\n",
       "      <td>TELANGANA</td>\n",
       "      <td>KHAMMAM</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>ANUGUL</td>\n",
       "      <td>WEST BENGAL</td>\n",
       "      <td>KOLKATA</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Week Destination District    Origin State Origin District  \\\n",
       "0           0    18               ANUGUL  ANDHRA PRADESH   EAST GODAVARI   \n",
       "1           1    18               ANUGUL  ANDHRA PRADESH    VIZIANAGARAM   \n",
       "2           2    19               ANUGUL  ANDHRA PRADESH   EAST GODAVARI   \n",
       "3           3    19               ANUGUL       TELANGANA         KHAMMAM   \n",
       "4           4    19               ANUGUL     WEST BENGAL         KOLKATA   \n",
       "\n",
       "   Train Passengers  Road Passengers  \n",
       "0                 0                1  \n",
       "1                 0                1  \n",
       "2                 0                3  \n",
       "3                 0                1  \n",
       "4                 0                5  "
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_influx_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = '\\\"TAMIL NADU\\\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origin State</th>\n",
       "      <th>Origin District</th>\n",
       "      <th>RP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>TIRUPPUR</td>\n",
       "      <td>2584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>CHENNAI</td>\n",
       "      <td>2209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>KANCHIPURAM</td>\n",
       "      <td>1462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>COIMBATORE</td>\n",
       "      <td>1323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>THIRUVALLUR</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>ERODE</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>CHENGALPATTU</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>VELLORE</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>NAMAKKAL</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>KRISHNAGIRI</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>THIRUVARUR</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>PUDUKKOTTAI</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>SALEM</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>CUDDALORE</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>RAMANATHAPURAM</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>VIRUDHUNAGAR</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>VILLUPURAM</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>TIRUVANNAMALAI</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>MADURAI</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>TUTICORIN</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>TIRUNELVELI</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>DINDIGUL</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>KARUR</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>SIVAGANGA</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>TIRUCHIRAPPALLI</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>NAGAPATTINAM</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>KANNIYAKUMARI</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>Tirupathur</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>DHARMAPURI</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>PERAMBALUR</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>THANJAVUR</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>Ariyalur</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>THENI</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>Ranipet</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>KALLAKURICHI</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>THE NILGIRIS</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>TENKASI</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>NORTH DISTRICT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Origin State  Origin District    RP\n",
       "0    TAMIL NADU         TIRUPPUR  2584\n",
       "1    TAMIL NADU          CHENNAI  2209\n",
       "2    TAMIL NADU      KANCHIPURAM  1462\n",
       "3    TAMIL NADU       COIMBATORE  1323\n",
       "4    TAMIL NADU      THIRUVALLUR  1045\n",
       "5    TAMIL NADU            ERODE   628\n",
       "6    TAMIL NADU     CHENGALPATTU   268\n",
       "7    TAMIL NADU          VELLORE   207\n",
       "8    TAMIL NADU         NAMAKKAL   197\n",
       "9    TAMIL NADU      KRISHNAGIRI   184\n",
       "10   TAMIL NADU       THIRUVARUR   122\n",
       "11   TAMIL NADU      PUDUKKOTTAI    86\n",
       "12   TAMIL NADU            SALEM    81\n",
       "13   TAMIL NADU        CUDDALORE    81\n",
       "14   TAMIL NADU   RAMANATHAPURAM    66\n",
       "15   TAMIL NADU     VIRUDHUNAGAR    55\n",
       "16   TAMIL NADU       VILLUPURAM    55\n",
       "17   TAMIL NADU   TIRUVANNAMALAI    52\n",
       "18   TAMIL NADU          MADURAI    49\n",
       "19   TAMIL NADU        TUTICORIN    42\n",
       "20   TAMIL NADU      TIRUNELVELI    34\n",
       "21   TAMIL NADU         DINDIGUL    33\n",
       "22   TAMIL NADU            KARUR    30\n",
       "23   TAMIL NADU        SIVAGANGA    27\n",
       "24   TAMIL NADU  TIRUCHIRAPPALLI    19\n",
       "25   TAMIL NADU     NAGAPATTINAM    19\n",
       "26   TAMIL NADU    KANNIYAKUMARI    19\n",
       "27   TAMIL NADU       Tirupathur    17\n",
       "28   TAMIL NADU       DHARMAPURI    16\n",
       "29   TAMIL NADU       PERAMBALUR    13\n",
       "30   TAMIL NADU        THANJAVUR    12\n",
       "31   TAMIL NADU         Ariyalur    11\n",
       "32   TAMIL NADU            THENI     9\n",
       "33   TAMIL NADU          Ranipet     6\n",
       "34   TAMIL NADU     KALLAKURICHI     6\n",
       "35   TAMIL NADU     THE NILGIRIS     4\n",
       "36   TAMIL NADU          TENKASI     3\n",
       "37   TAMIL NADU   NORTH DISTRICT     1"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandasql.sqldf('SELECT \"ORIGIN STATE\", \"ORIGIN DISTRICT\", SUM(\"ROAD PASSENGERS\") as RP'\n",
    "               +' FROM weekly_influx_data WHERE \"ORIGIN STATE\" = '+state+' GROUP BY \"ORIGIN DISTRICT\"'\n",
    "               + ' ORDER BY RP DESC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origin State</th>\n",
       "      <th>Origin District</th>\n",
       "      <th>TP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>CHENNAI</td>\n",
       "      <td>14258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>THIRUVALLUR</td>\n",
       "      <td>13816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>TIRUPPUR</td>\n",
       "      <td>10735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>COIMBATORE</td>\n",
       "      <td>6988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>KANCHIPURAM</td>\n",
       "      <td>4511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TAMIL NADU</td>\n",
       "      <td>ERODE</td>\n",
       "      <td>3561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Origin State Origin District     TP\n",
       "0   TAMIL NADU         CHENNAI  14258\n",
       "1   TAMIL NADU     THIRUVALLUR  13816\n",
       "2   TAMIL NADU        TIRUPPUR  10735\n",
       "3   TAMIL NADU      COIMBATORE   6988\n",
       "4   TAMIL NADU     KANCHIPURAM   4511\n",
       "5   TAMIL NADU           ERODE   3561"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandasql.sqldf('SELECT \"ORIGIN STATE\", \"ORIGIN DISTRICT\", SUM(\"TRAIN PASSENGERS\")+sum(\"ROAD PASSENGERS\") as TP'\n",
    "               +' FROM weekly_influx_data WHERE \"ORIGIN STATE\" = '+ state + ' GROUP BY \"ORIGIN DISTRICT\"'\n",
    "               + ' ORDER BY TP DESC LIMIT 6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_population = pd.read_excel('covid_processed.xlsx', sheet_name=\"District Populations\", skiprows=0)\n",
    "city_population = pd.read_excel('covid_processed.xlsx', sheet_name=\"City Populations\", skiprows=0)\n",
    "state_population = pd.read_excel('state_parameters.xlsx', sheet_name=\"Influx\", skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_pop_dict = dict()\n",
    "district_pop_dict = dict()\n",
    "state_pop_dict = dict()\n",
    "for i in range(district_population.shape[0]):\n",
    "    row = district_population.loc[i]\n",
    "    district_name = row['District'].upper()\n",
    "    district_pop_dict[district_name] = row['Population']\n",
    "for i in range(city_population.shape[0]):\n",
    "    row = city_population.loc[i]\n",
    "    city_name = row['Name'].upper()\n",
    "    city_pop_dict[city_name] = row['Population']\n",
    "for i in range(state_population.shape[0]):\n",
    "    row = state_population.loc[i]\n",
    "    state_name = row['State'].upper()\n",
    "    state_pop_dict[state_name] = row['Population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "imp_states = [\"TAMIL NADU\", \"WEST BENGAL\", \"TELANGANA\", \"MAHARASHTRA\", \"ANDHRA PRADESH\", \"KARNATAKA\", \"GUJARAT\"]\n",
    "n_states = len(imp_states)\n",
    "row_list = []\n",
    "max_n_districts = 6\n",
    "n_India_pop = 1250 * 10**6\n",
    "n_states_sum_pop = 0\n",
    "for state in imp_states:\n",
    "    state_data = pandasql.sqldf('SELECT \"ORIGIN STATE\", \"ORIGIN DISTRICT\", SUM(\"TRAIN PASSENGERS\")+sum(\"ROAD PASSENGERS\") as TP'\n",
    "               +' FROM weekly_influx_data WHERE \"ORIGIN STATE\" = \\\"'+ state + '\\\" GROUP BY \"ORIGIN DISTRICT\"'\n",
    "               + ' ORDER BY TP DESC')\n",
    "    n_districts = state_data.shape[0]\n",
    "    nrow_other = dict()\n",
    "    nrow_other['State'] = state\n",
    "    nrow_other['District'] = 'OTHER'\n",
    "    nrow_other['Total Passengers'] = 0\n",
    "    nsum_pop = 0\n",
    "    n_state_pop = 0\n",
    "    if state in state_pop_dict:\n",
    "        n_state_pop = state_pop_dict[state]\n",
    "    n_states_sum_pop += n_state_pop\n",
    "        \n",
    "    row_list.append(nrow_other)\n",
    "    for i in range(n_districts):\n",
    "        if i < max_n_districts:\n",
    "            row = state_data.loc[i]\n",
    "            nrow = dict()\n",
    "            nrow['State'] = state\n",
    "            nrow['District'] = row['Origin District']\n",
    "            nrow['Total Passengers'] = row['TP']\n",
    "            nrow_pop = 0\n",
    "            if nrow['District'] in city_pop_dict:\n",
    "                nrow_pop = city_pop_dict[nrow['District']]\n",
    "            elif nrow['District'] in district_pop_dict:\n",
    "                nrow_pop = district_pop_dict[nrow['District']]\n",
    "            nrow['Population'] = nrow_pop\n",
    "            nsum_pop += nrow_pop\n",
    "            row_list.append(nrow)\n",
    "        else:\n",
    "            nrow_other['Total Passengers'] += row['TP']\n",
    "    nrow_other['Population'] = n_state_pop - nsum_pop\n",
    "    \n",
    "    \n",
    "nrow_other = dict()\n",
    "nrow_other['State'] = 'OTHER'\n",
    "nrow_other['District'] = 'OTHER'\n",
    "nrow_other['Total Passengers'] = 0\n",
    "nrow_other['Population'] = n_India_pop - n_states_sum_pop\n",
    "row_list.append(nrow_other)\n",
    "state_data = pandasql.sqldf('SELECT \"ORIGIN STATE\", \"ORIGIN DISTRICT\", SUM(\"TRAIN PASSENGERS\")+sum(\"ROAD PASSENGERS\") as TP'\n",
    "               +' FROM weekly_influx_data GROUP BY \"ORIGIN DISTRICT\"'\n",
    "               + ' ORDER BY TP DESC')\n",
    "nrows = state_data.shape[0]\n",
    "for i in range(nrows):\n",
    "    row = state_data.loc[i]\n",
    "    if row['Origin State'] in imp_states:\n",
    "        continue\n",
    "    else:\n",
    "        nrow_other['Total Passengers'] += row['TP']\n",
    "\n",
    "writeDFToExcel(row_list, 'covid_processed_important_states.xlsx', 'Important States')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandasql\n",
    "Odisha_data = pandasql.sqldf('SELECT DISTINCT \"DESTINATION DISTRICT\" FROM road_processed_data')\n",
    "all_Odisha_districts = []\n",
    "for i in range(Odisha_data.shape[0]):\n",
    "    row = Odisha_data.loc[i]\n",
    "    district = row['Destination District'].upper()\n",
    "    all_Odisha_districts.append(district)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "railway_processed_data = pd.read_excel('covid_processed.xlsx', sheet_name=\"Railways\", skiprows=0)\n",
    "road_processed_data = pd.read_excel('covid_processed.xlsx', sheet_name=\"Roadways\", skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Railways 4850\n"
     ]
    }
   ],
   "source": [
    "# import datetime\n",
    "imp_states = [\"TAMIL NADU\", \"WEST BENGAL\", \"TELANGANA\", \"MAHARASHTRA\", \"ANDHRA PRADESH\", \"KARNATAKA\", \"GUJARAT\"]\n",
    "imp_districts_data = pd.read_excel('covid_processed_important_states.xlsx', sheet_name=\"Important States\", skiprows=0)\n",
    "imp_districts = []\n",
    "\n",
    "for i in range(imp_districts_data.shape[0]):\n",
    "    row = imp_districts_data.loc[i]\n",
    "    district_name = row['District'].upper()\n",
    "    if district_name != 'OTHER':\n",
    "        imp_districts.append(district_name)\n",
    "        \n",
    "mydict = dict()\n",
    "nrows = road_processed_data.shape[0]\n",
    "row_list = []\n",
    "for week in range(8,41):\n",
    "    for destination_district in all_Odisha_districts:\n",
    "        key = (week, destination_district, 'OTHER', 'OTHER')\n",
    "        nrow = dict()\n",
    "        nrow['Week'] = week\n",
    "        nrow['Destination District'] = destination_district\n",
    "        nrow['Origin State'] = 'OTHER'\n",
    "        nrow['Origin District'] = 'OTHER'\n",
    "        nrow['Train Passengers'] = 0\n",
    "        nrow['Road Passengers'] = 0\n",
    "\n",
    "        mydict[key] = nrow\n",
    "        row_list.append(nrow)\n",
    "        for i in range(len(imp_states)):\n",
    "            origin_state = imp_states[i]\n",
    "            key = (week, destination_district, origin_state, 'OTHER')\n",
    "            nrow = dict()\n",
    "            nrow['Week'] = week\n",
    "            nrow['Destination District'] = destination_district\n",
    "            nrow['Origin State'] = origin_state\n",
    "            nrow['Origin District'] = 'OTHER'\n",
    "            nrow['Train Passengers'] = 0\n",
    "            nrow['Road Passengers'] = 0\n",
    "            mydict[key] = nrow\n",
    "            row_list.append(nrow)\n",
    "            for j in range(6):            \n",
    "                origin_district = imp_districts[i*6+j]\n",
    "                key = (week, destination_district, origin_state, origin_district)\n",
    "                nrow = dict()\n",
    "                nrow['Week'] = week\n",
    "                nrow['Destination District'] = destination_district\n",
    "                nrow['Origin State'] = origin_state\n",
    "                nrow['Origin District'] = origin_district\n",
    "                nrow['Train Passengers'] = 0\n",
    "                nrow['Road Passengers'] = 0\n",
    "                mydict[key] = nrow\n",
    "                row_list.append(nrow)\n",
    "    \n",
    "\n",
    "for i in range(nrows):\n",
    "    row = road_processed_data.loc[i]\n",
    "    week = row['Arrival Date'].date().isocalendar()[1]\n",
    "    destination_district = row['Destination District']\n",
    "    origin_district = row['Origin District']\n",
    "    origin_state = row['Origin State']\n",
    "    try:\n",
    "        destination_district = destination_district.upper()\n",
    "        origin_district = origin_district.upper()\n",
    "        origin_state = origin_state.upper()\n",
    "    except:\n",
    "        print(i, destination_district, origin_state, origin_district)\n",
    "        \n",
    "        \n",
    "    if origin_state not in imp_states:\n",
    "        origin_state = 'OTHER'\n",
    "        origin_district = 'OTHER'\n",
    "    if origin_district not in imp_districts:\n",
    "        origin_district = 'OTHER'\n",
    "    \n",
    "    key = (week, destination_district, origin_state, origin_district)\n",
    "    if key not in mydict:\n",
    "        continue\n",
    "    else:\n",
    "        nrow = mydict[key]\n",
    "    nrow['Road Passengers'] += row['Number of passengers']\n",
    "\n",
    "nrows = railway_processed_data.shape[0]\n",
    "print(\"Railways\", nrows)\n",
    "for i in range(nrows):\n",
    "    row = railway_processed_data.loc[i]\n",
    "    week = row['Arrival Date'].date().isocalendar()[1]\n",
    "    destination_district = row['Destination District']\n",
    "    origin_district = row['Origin District']\n",
    "    origin_state = row['Origin State']\n",
    "    try:\n",
    "        destination_district = destination_district.upper()\n",
    "        origin_district = origin_district.upper()\n",
    "        origin_state = origin_state.upper()\n",
    "    except:\n",
    "        print(i, destination_district, origin_state, origin_district)\n",
    "        \n",
    "    if origin_state not in imp_states:\n",
    "        origin_state = 'OTHER'\n",
    "        origin_district = 'OTHER'\n",
    "    if origin_district not in imp_districts:\n",
    "        origin_district = 'OTHER'\n",
    "        \n",
    "    key = (week, destination_district, origin_state, origin_district)\n",
    "    if key not in mydict:\n",
    "        continue\n",
    "    else:\n",
    "        nrow = mydict[key]\n",
    "    \n",
    "    nrow['Train Passengers'] += row['Number of passengers']\n",
    "\n",
    "# writeDFToExcel(row_list, 'important_states_weekly_influx.xlsx', 'Weekly Influx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN TAMIL NADU\n",
      "WB WEST BENGAL\n",
      "TG TELANGANA\n",
      "MH MAHARASHTRA\n",
      "AP ANDHRA PRADESH\n",
      "KA KARNATAKA\n",
      "GJ GUJARAT\n"
     ]
    }
   ],
   "source": [
    "imp_states_code = [\"TN\", \"WB\", \"TG\", \"MH\", \"AP\", \"KA\", \"GJ\"]\n",
    "imp_code_states_map = {\"TN\":\"TAMIL NADU\", \"WB\" :\"WEST BENGAL\", \"TG\":\"TELANGANA\", \"MH\":\"MAHARASHTRA\", \n",
    "                       \"AP\":\"ANDHRA PRADESH\", \"KA\":\"KARNATAKA\", \"GJ\":\"GUJARAT\"}\n",
    "for key in imp_code_states_map:\n",
    "    print(key, imp_code_states_map[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CHENNAI', 'THIRUVALLUR', 'TIRUPPUR', 'COIMBATORE', 'KANCHIPURAM', 'ERODE', 'KOLKATA', 'MEDINIPUR EAST', 'HOWRAH', 'MEDINIPUR WEST', '24 PARAGANAS NORTH', 'MURSHIDABAD', 'RANGA REDDY', 'HYDERABAD', 'MEDCHAL MALKAJGIRI', 'SANGAREDDY', 'YADADRI BHUVANAGIRI', 'KARIMNAGAR', 'PUNE', 'MUMBAI', 'THANE', 'PALGHAR', 'RAIGAD', 'JALGAON', 'VISAKHAPATANAM', 'GUNTUR', 'CHITTOOR', 'EAST GODAVARI', 'KRISHNA', 'SRIKAKULAM', 'BENGALURU URBAN', 'BENGALURU RURAL', 'RAMANAGARA', 'BALLARI', 'KOLAR', 'CHIKKABALLAPURA', 'SURAT', 'AHMEDABAD', 'RAJKOT', 'MORBI', 'AMRELI', 'VALSAD']\n",
      "['RANGA REDDY', 'HYDERABAD', 'MEDCHAL MALKAJGIRI', 'SANGAREDDY', 'YADADRI BHUVANAGIRI', 'KARIMNAGAR', 'OTHER']\n"
     ]
    }
   ],
   "source": [
    "print(imp_districts)\n",
    "TG_districts = imp_districts[12:18]\n",
    "TG_districts.append(\"OTHER\")\n",
    "print(TG_districts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'states_district_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-954c69c5a2a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates_district_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'states_district_data' is not defined"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "mydict = dict()\n",
    "row_list = []\n",
    "with open ('../data/data-all.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    print(len(data))\n",
    "    nrows = len(states_district_data)\n",
    "    i = 0\n",
    "    for key in data:\n",
    "        i += 1\n",
    "        mydate = key\n",
    "        mydate = datetime.strptime(mydate,'%Y-%m-%d')\n",
    "        mydate = mydate.date()\n",
    "        week = mydate.isocalendar()[1]\n",
    "        daily_data = data[key]\n",
    "        for state_code in daily_data:\n",
    "            if state_code in imp_states_code:\n",
    "                state_name = imp_code_states_map[state_code]\n",
    "            else:\n",
    "                state_name = 'OTHER'\n",
    "            state_data = daily_data[state_code]\n",
    "            if \"districts\" in state_data:\n",
    "                state_district_data = state_data[\"districts\"]\n",
    "                for district_name in state_district_data:\n",
    "                    old_district_name = district_name\n",
    "                    individual_district_data = state_district_data[district_name]\n",
    "                    \n",
    "                    if state_name!=\"OTHER\":\n",
    "                        if old_district_name == \"North 24 Parganas\":\n",
    "                            old_district_name = \"24 PARAGANAS NORTH\"\n",
    "                        elif  old_district_name == \"Purba Medinipur\":\n",
    "                            old_district_name = \"MEDINIPUR EAST\"\n",
    "                        elif  old_district_name == \"Paschim Medinipur\":\n",
    "                            old_district_name = \"MEDINIPUR WEST\"\n",
    "                        elif  old_district_name == \"Kancheepuram\":\n",
    "                            old_district_name = \"KANCHIPURAM\"\n",
    "                        elif  old_district_name == \"Visakhapatnam\":\n",
    "                            old_district_name = \"Visakhapatanam\"\n",
    "#                         elif  old_district_name == \"Ramanagara\":\n",
    "#                             old_district_name = \"Ramanagar\"\n",
    "#                         elif  old_district_name == \"\":\n",
    "#                             old_district_name = \"\"\n",
    "#                         elif  old_district_name == \"\":\n",
    "#                             old_district_name = \"\"\n",
    "#                         elif  old_district_name == \"\":\n",
    "#                             old_district_name = \"\"\n",
    "                    district_name = old_district_name\n",
    "#                     if district_name in ['Ramanagara', 'Kolar', 'Amreli']\n",
    "#                         print(district_name)\n",
    "                    \n",
    "                    district_name = district_name.upper()\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    if state_name == 'OTHER':\n",
    "                        district_name = 'OTHER'\n",
    "                    elif old_district_name == \"Unknown\":\n",
    "                        district_name = 'OTHER'\n",
    "                    elif district_name not in imp_districts:\n",
    "                        district_name = 'OTHER'\n",
    "                    \n",
    "                    if state_name != 'OTHER' and district_name == 'OTHER':\n",
    "                        print(mydate, state_code, old_district_name, state_name, district_name)\n",
    "                    \n",
    "                    district_name = district_name.upper()\n",
    "                    \n",
    "                    nrowkey = (week, state_name, district_name)\n",
    "                    if nrowkey in mydict:\n",
    "                        nrow = mydict[nrowkey]\n",
    "                    else:\n",
    "                        nrow = dict()\n",
    "                        nrow['Week'] = week\n",
    "                        nrow['State'] = state_name\n",
    "                        nrow['District'] = district_name\n",
    "                        nrow['Confirmed'] = 0\n",
    "                        nrow['Recovered'] = 0\n",
    "                        nrow['Deceased'] = 0\n",
    "                        nrow['Active cases'] = 0\n",
    "                        nrow['Tested'] = 0\n",
    "                        mydict[nrowkey] = nrow\n",
    "                        row_list.append(nrow)                        \n",
    "    \n",
    "                    if \"total\" in individual_district_data:\n",
    "                        total_data = individual_district_data['total']\n",
    "                        if \"confirmed\" in total_data:\n",
    "                            nrow['Confirmed'] += total_data['confirmed']\n",
    "#                         else:\n",
    "#                             print(mydate, state_code, old_district_name, state_name, district_name)\n",
    "                        if \"recovered\" in total_data:\n",
    "                            nrow['Recovered'] += total_data['recovered']\n",
    "                        if \"deceased\" in total_data:\n",
    "                            nrow['Deceased'] += total_data['deceased']\n",
    "                        nrow['Active cases'] = nrow['Confirmed'] - nrow['Recovered'] - nrow['Deceased']\n",
    "                        if \"tested\" in total_data:\n",
    "                            nrow['Tested'] += total_data['tested']\n",
    "for key in mydict:\n",
    "    nrow['Confirmed'] /= 7\n",
    "    nrow['Recovered'] /= 7\n",
    "    nrow['Deceased'] /= 7\n",
    "    nrow['Active cases'] /=7\n",
    "    \n",
    "# writeDFToExcel(row_list, 'important_states_weekly_covid.xlsx', 'Weekly Covid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of districts 30\n",
      "172\n",
      "720\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "district_population_data = pd.read_excel('../data/districtPopulations.xlsx', sheet_name=\"District Populations\", skiprows=0)\n",
    "odisha_district_population = dict()\n",
    "nrows = district_population_data.shape[0]\n",
    "for i in range(nrows):\n",
    "    row = district_population_data.loc[i]\n",
    "    if row['State'] != 'Odisha':\n",
    "        continue\n",
    "    odisha_district_population[str.upper(row['District'])] = row['Population']\n",
    "\n",
    "mydict = dict()\n",
    "row_list = []\n",
    "for week in range(10,34):\n",
    "    for district in all_Odisha_districts:\n",
    "        nrowkey = (week, district)\n",
    "        nrow = dict()\n",
    "        nrow['Week'] = week\n",
    "        nrow['District'] = district\n",
    "        nrow['Confirmed'] = 0\n",
    "        nrow['Recovered'] = 0\n",
    "        nrow['Deceased'] = 0\n",
    "        nrow['Active cases'] = 0\n",
    "        nrow['Tested'] = 0\n",
    "        nrow['Population'] = odisha_district_population[district]\n",
    "        nrow['Susceptible'] = 0\n",
    "        nrow['theta_S_t'] = 0\n",
    "        nrow['theta_C_t'] = 0\n",
    "        nrow['theta_R_t'] = 0\n",
    "        nrow['theta_D_t'] = 0\n",
    "        mydict[nrowkey] = nrow\n",
    "        row_list.append(nrow)                        \n",
    "\n",
    "summary_dict = dict()\n",
    "summary_row_list = []\n",
    "print(\"number of districts\", len(all_Odisha_districts))\n",
    "for district in all_Odisha_districts:\n",
    "    nrowkey = district\n",
    "    nrow = dict()\n",
    "    nrow['District'] = district\n",
    "    nrow['Confirmed'] = 0\n",
    "    nrow['Recovered'] = 0\n",
    "    nrow['Deceased'] = 0\n",
    "    nrow['Active cases'] = 0\n",
    "    nrow['Tested'] = 0\n",
    "    nrow['Population'] = odisha_district_population[district]\n",
    "    nrow['Susceptible'] = nrow['Population']\n",
    "    nrow['theta_S_t'] = 1\n",
    "    nrow['theta_C_t'] = 0\n",
    "    nrow['theta_R_t'] = 0\n",
    "    nrow['theta_D_t'] = 0\n",
    "    summary_dict[nrowkey] = nrow\n",
    "    summary_row_list.append(nrow)\n",
    "\n",
    "with open ('../data/data-all.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    print(len(data))\n",
    "    i = 0\n",
    "    for key in data:\n",
    "        i += 1\n",
    "        mydate = key\n",
    "        mydate = datetime.strptime(mydate,'%Y-%m-%d')\n",
    "        mydate = mydate.date()\n",
    "        week = mydate.isocalendar()[1]\n",
    "        daily_data = data[key]\n",
    "        for state_code in daily_data:\n",
    "            if state_code != \"OR\":\n",
    "                continue\n",
    "            state_name = \"ODISHA\"\n",
    "            state_data = daily_data[state_code]\n",
    "            if \"districts\" in state_data:\n",
    "                state_district_data = state_data[\"districts\"]\n",
    "                for district_name in state_district_data:\n",
    "                    old_district_name = district_name\n",
    "                    if old_district_name == \"Subarnapur\":\n",
    "                        district_name = \"SONEPUR\"\n",
    "                    elif old_district_name == \"Nabarangapur\":\n",
    "                        district_name = str.upper(\"Nabarangpur\")\n",
    "                    elif old_district_name == \"Jajpur\":\n",
    "                        district_name = str.upper(\"Jajapur\")\n",
    "                    elif old_district_name == \"Jagatsinghpur\":\n",
    "                        district_name = str.upper(\"Jagatsinghapur\")\n",
    "                    elif old_district_name == \"Balasore\":\n",
    "                        district_name = str.upper(\"BALESHWAR\")\n",
    "                    elif old_district_name == \"Angul\":\n",
    "                        district_name = str.upper(\"Anugul\")\n",
    "                        \n",
    "                    individual_district_data = state_district_data[old_district_name]\n",
    "                    district_name = district_name.upper()\n",
    "                    \n",
    "                    nrowkey = (week, district_name)\n",
    "                    if nrowkey in mydict:\n",
    "                        nrow = mydict[nrowkey]\n",
    "                    else:\n",
    "                        continue\n",
    "    \n",
    "                    if \"total\" in individual_district_data:\n",
    "                        total_data = individual_district_data['total']\n",
    "                        if \"confirmed\" in total_data:\n",
    "                            nrow['Confirmed'] += total_data['confirmed']\n",
    "                        if \"recovered\" in total_data:\n",
    "                            nrow['Recovered'] += total_data['recovered']\n",
    "                        if \"deceased\" in total_data:\n",
    "                            nrow['Deceased'] += total_data['deceased']\n",
    "                        nrow['Active cases'] = nrow['Confirmed'] - nrow['Recovered'] - nrow['Deceased']\n",
    "                        if \"tested\" in total_data:\n",
    "                            nrow['Tested'] += total_data['tested']\n",
    "for key in mydict:\n",
    "    nrow = mydict[key]\n",
    "    nrow['Confirmed'] /= 7\n",
    "    nrow['Recovered'] /= 7\n",
    "    nrow['Deceased'] /= 7\n",
    "    nrow['Active cases'] /=7\n",
    "    nrow['Susceptible'] = nrow['Population'] - nrow['Confirmed']\n",
    "    nrow['theta_S_t'] = nrow['Susceptible'] / nrow['Population']\n",
    "    nrow['theta_C_t'] = nrow['Confirmed'] / nrow['Population']\n",
    "    nrow['theta_R_t'] = nrow['Recovered'] / nrow['Population']\n",
    "    nrow['theta_D_t'] = nrow['Deceased'] / nrow['Population']\n",
    "    summary_row = summary_dict[nrow['District']]\n",
    "    \n",
    "    summary_row['Confirmed'] = max(summary_row['Confirmed'], nrow['Confirmed'])\n",
    "    summary_row['Recovered'] = max(summary_row['Recovered'], nrow['Recovered'])\n",
    "    summary_row['Deceased'] = max(summary_row['Deceased'], nrow['Deceased'])\n",
    "    summary_row['Active cases'] = max(summary_row['Active cases'], nrow['Active cases'])\n",
    "    summary_row['Tested'] = max(summary_row['Tested'], nrow['Tested'])\n",
    "    summary_row['Susceptible'] = min(summary_row['Susceptible'], nrow['Susceptible'])\n",
    "    summary_row['theta_S_t'] = min(summary_row['theta_S_t'], nrow['theta_S_t'])\n",
    "    summary_row['theta_C_t'] = max(summary_row['theta_C_t'], nrow['theta_C_t'])\n",
    "    summary_row['theta_R_t'] = max(summary_row['theta_R_t'], nrow['theta_R_t'])\n",
    "    summary_row['theta_D_t'] = max(summary_row['theta_D_t'], nrow['theta_D_t'])\n",
    "    \n",
    "    \n",
    "writeDFToExcel(row_list, 'Odisha_weekly_covid.xlsx', 'Weekly Covid')\n",
    "writeDFToExcel(summary_row_list, 'Odisha_summary_covid.xlsx', 'Covid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_covid_data = pd.read_excel('important_states_weekly_covid.xlsx', sheet_name=\"Weekly Covid\", skiprows=0)\n",
    "weekly_influx_data = pd.read_excel('important_states_weekly_influx.xlsx', sheet_name=\"Weekly Influx\", skiprows=0)\n",
    "important_state_district_data = pd.read_excel('covid_processed_important_states.xlsx', sheet_name=\"Important States\", skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VISAKHAPATANAM 22\n",
      "VISAKHAPATANAM 173\n",
      "VISAKHAPATANAM 339\n",
      "VISAKHAPATANAM 479\n",
      "VISAKHAPATANAM 557\n",
      "VISAKHAPATANAM 653\n",
      "VISAKHAPATANAM 777\n",
      "VISAKHAPATANAM 1244\n",
      "VISAKHAPATANAM 1712\n",
      "VISAKHAPATANAM 2798\n",
      "VISAKHAPATANAM 4169\n",
      "VISAKHAPATANAM 7923\n",
      "VISAKHAPATANAM 11901\n",
      "VISAKHAPATANAM 30111\n",
      "VISAKHAPATANAM 69327\n",
      "VISAKHAPATANAM 117397\n",
      "VISAKHAPATANAM 157511\n",
      "1300\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "3.762305089081979e-06   0   4\n",
      "2.3514406806762368e-05   0   25\n",
      "9.405762722704946e-06   0   10\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "1.410864408405742e-05   0   15\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "6.584033905893463e-06   0   7\n",
      "3.292016952946731e-05   0   35\n",
      "4.702881361352473e-06   0   5\n",
      "7.524610178163958e-06   0   8\n",
      "0.0   0   0\n",
      "1.1286915267245937e-05   0   12\n",
      "0.0   0   0\n",
      "1.8811525445409895e-06   0   2\n",
      "3.762305089081979e-06   0   4\n",
      "2.163325426222138e-05   0   23\n",
      "1.1286915267245937e-05   0   12\n",
      "1.3168067811786925e-05   0   14\n",
      "7.524610178163958e-06   0   8\n",
      "5.643457633622968e-06   0   6\n",
      "9.405762722704947e-07   0   1\n",
      "0.0   0   0\n",
      "8.465186450434452e-06   0   9\n",
      "5.831572888077067e-05   0   62\n",
      "0.0   0   0\n",
      "9.405762722704947e-07   0   1\n",
      "4.702881361352473e-06   0   5\n",
      "8.465186450434452e-06   0   9\n",
      "2.5395559351303356e-05   0   27\n",
      "2.821728816811484e-06   0   3\n",
      "5.643457633622968e-06   0   6\n",
      "5.643457633622968e-06   0   6\n",
      "0.0   0   0\n",
      "1.2227491539516431e-05   0   13\n",
      "0.0   0   0\n",
      "1.3168067811786925e-05   0   14\n",
      "1.3168067811786925e-05   0   14\n",
      "3.4801322074008306e-05   0   37\n",
      "1.6930372900868904e-05   0   18\n",
      "1.034633899497544e-05   0   11\n",
      "0.0   0   0\n",
      "3.009844071265583e-05   0   32\n",
      "0.0   0   0\n",
      "1.6930372900868904e-05   0   18\n",
      "7.524610178163958e-06   0   8\n",
      "2.633613562357385e-05   0   28\n",
      "5.549400006395919e-05   0   59\n",
      "0.0   0   0\n",
      "5.643457633622968e-06   0   6\n",
      "9.405762722704946e-06   0   10\n",
      "2.821728816811484e-06   0   3\n",
      "2.821728816811484e-06   0   3\n",
      "1.9752101717680387e-05   0   21\n",
      "4.326650852444276e-05   0   46\n",
      "4.702881361352473e-06   0   5\n",
      "4.702881361352473e-06   0   5\n",
      "9.405762722704946e-06   0   10\n",
      "9.405762722704947e-07   0   1\n",
      "0.0005464748141891574   576   5\n",
      "4.702881361352473e-06   0   5\n",
      "5.643457633622968e-06   6   0\n",
      "6.584033905893463e-06   0   7\n",
      "1.8811525445409895e-06   0   2\n",
      "5.643457633622968e-06   0   6\n",
      "0.0   0   0\n",
      "8.465186450434452e-06   0   9\n",
      "1.8811525445409895e-06   0   2\n",
      "3.009844071265583e-05   0   32\n",
      "6.584033905893463e-06   0   7\n",
      "8.465186450434452e-06   0   9\n",
      "4.702881361352473e-06   0   5\n",
      "3.9504203435360774e-05   28   14\n",
      "0.0   0   0\n",
      "1.410864408405742e-05   10   5\n",
      "0.0   0   0\n",
      "3.7623050890819786e-05   0   40\n",
      "0.0002652425087802795   0   282\n",
      "1.034633899497544e-05   0   11\n",
      "8.465186450434452e-06   0   9\n",
      "8.465186450434452e-06   0   9\n",
      "4.702881361352473e-06   4   1\n",
      "3.9504203435360774e-05   42   0\n",
      "1.1286915267245937e-05   0   12\n",
      "6.019688142531166e-05   0   64\n",
      "9.405762722704947e-07   0   1\n",
      "0.0   0   0\n",
      "8.465186450434452e-06   0   9\n",
      "1.034633899497544e-05   0   11\n",
      "0.0001796500680036645   163   28\n",
      "2.821728816811484e-06   0   3\n",
      "1.1286915267245937e-05   6   6\n",
      "1.8811525445409895e-06   0   2\n",
      "0.0   0   0\n",
      "6.584033905893463e-06   0   7\n",
      "0.0   0   0\n",
      "3.762305089081979e-06   0   4\n",
      "1.8811525445409895e-06   0   2\n",
      "1.410864408405742e-05   0   15\n",
      "9.405762722704947e-07   0   1\n",
      "2.821728816811484e-06   0   3\n",
      "0.0   0   0\n",
      "8.465186450434452e-06   0   9\n",
      "1.8811525445409895e-06   0   2\n",
      "0.0   0   0\n",
      "9.405762722704947e-07   0   1\n",
      "1.6930372900868904e-05   0   18\n",
      "0.00020222389853815636   10   205\n",
      "4.608823734125424e-05   0   49\n",
      "9.405762722704947e-07   0   1\n",
      "1.8811525445409895e-06   0   2\n",
      "0.0   0   0\n",
      "1.8811525445409893e-05   12   8\n",
      "1.1286915267245937e-05   0   12\n",
      "6.866206787574611e-05   0   73\n",
      "9.405762722704947e-07   0   1\n",
      "0.0   0   0\n",
      "1.410864408405742e-05   0   15\n",
      "0.0   0   0\n",
      "2.2573830534491874e-05   0   24\n",
      "1.8811525445409895e-06   0   2\n",
      "1.5049220356327916e-05   0   16\n",
      "9.405762722704947e-07   0   1\n",
      "0.0   0   0\n",
      "9.405762722704946e-06   0   10\n",
      "0.0   0   0\n",
      "9.405762722704947e-07   0   1\n",
      "0.0   0   0\n",
      "9.217647468250848e-05   70   28\n",
      "7.524610178163958e-06   0   8\n",
      "1.2227491539516431e-05   0   13\n",
      "0.0   0   0\n",
      "7.524610178163958e-06   0   8\n",
      "0.0   0   0\n",
      "1.8811525445409895e-06   0   2\n",
      "6.584033905893463e-06   0   7\n",
      "1.9752101717680387e-05   0   21\n",
      "3.103901698492633e-05   1   32\n",
      "5.643457633622968e-06   0   6\n",
      "9.405762722704947e-07   0   1\n",
      "2.4454983079032862e-05   0   26\n",
      "2.821728816811484e-06   0   3\n",
      "0.0   0   0\n",
      "2.163325426222138e-05   0   23\n",
      "6.113745769758215e-05   0   65\n",
      "1.3168067811786925e-05   0   14\n",
      "3.762305089081979e-06   0   4\n",
      "2.163325426222138e-05   0   23\n",
      "0.0   0   0\n",
      "6.584033905893463e-06   0   7\n",
      "0.0   0   0\n",
      "4.702881361352473e-06   0   5\n",
      "3.48013220740083e-05   22   15\n",
      "0.0   0   0\n",
      "5.643457633622968e-06   0   6\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "8.465186450434452e-06   0   9\n",
      "9.405762722704947e-07   1   0\n",
      "1.034633899497544e-05   0   11\n",
      "0.0   0   0\n",
      "1.8811525445409895e-06   0   2\n",
      "0.0   0   0\n",
      "9.405762722704947e-07   0   1\n",
      "2.821728816811484e-06   0   3\n",
      "3.386074580173781e-05   0   36\n",
      "1.034633899497544e-05   0   11\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "4.608823734125424e-05   0   49\n",
      "9.405762722704946e-06   0   10\n",
      "7.524610178163958e-06   0   8\n",
      "1.2227491539516431e-05   0   13\n",
      "0.0   0   0\n",
      "1.1286915267245937e-05   0   12\n",
      "4.702881361352473e-06   0   5\n",
      "1.2227491539516431e-05   0   13\n",
      "3.762305089081979e-06   0   4\n",
      "0.0   0   0\n",
      "6.584033905893463e-06   0   7\n",
      "0.0   0   0\n",
      "9.405762722704947e-07   0   1\n",
      "0.0   0   0\n",
      "1.2227491539516431e-05   0   13\n",
      "9.405762722704947e-07   0   1\n",
      "8.465186450434452e-06   0   9\n",
      "4.702881361352473e-06   0   5\n",
      "2.7276711895844345e-05   0   29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "4.326650852444276e-05   0   46\n",
      "3.762305089081979e-06   0   4\n",
      "9.405762722704947e-07   0   1\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "4.7969389885795227e-05   0   51\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "1.8811525445409895e-06   0   2\n",
      "7.524610178163958e-06   0   8\n",
      "4.702881361352473e-06   0   5\n",
      "9.405762722704947e-07   0   1\n",
      "9.405762722704947e-07   0   1\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "1.410864408405742e-05   0   15\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "1.410864408405742e-05   0   15\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "1.1286915267245937e-05   0   12\n",
      "1.8811525445409895e-06   0   2\n",
      "3.762305089081979e-06   0   4\n",
      "1.8811525445409895e-06   0   2\n",
      "0.0   0   0\n",
      "1.3168067811786925e-05   0   14\n",
      "9.405762722704947e-07   0   1\n",
      "2.821728816811484e-06   0   3\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "9.405762722704947e-07   0   1\n",
      "7.524610178163958e-06   0   8\n",
      "3.8563627163090283e-05   0   41\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "3.762305089081979e-06   0   4\n",
      "1.5049220356327916e-05   0   16\n",
      "4.702881361352473e-06   0   5\n",
      "1.8811525445409895e-06   0   2\n",
      "3.762305089081979e-06   0   4\n",
      "9.405762722704947e-07   0   1\n",
      "0.0   0   0\n",
      "5.643457633622968e-06   0   6\n",
      "0.0   0   0\n",
      "2.821728816811484e-06   0   3\n",
      "0.0   0   0\n",
      "3.7623050890819786e-05   0   40\n",
      "1.5049220356327916e-05   0   16\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "9.405762722704946e-06   0   10\n",
      "0.0   0   0\n",
      "6.584033905893463e-06   0   7\n",
      "3.762305089081979e-06   0   4\n",
      "3.7623050890819786e-05   0   40\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "1.8811525445409895e-06   0   2\n",
      "1.8811525445409895e-06   0   2\n",
      "1.8811525445409895e-06   0   2\n",
      "2.7276711895844345e-05   0   29\n",
      "2.4454983079032862e-05   0   26\n",
      "3.762305089081979e-06   0   4\n",
      "0.0   0   0\n",
      "1.410864408405742e-05   0   15\n",
      "0.0   0   0\n",
      "9.405762722704946e-06   0   10\n",
      "5.643457633622968e-06   0   6\n",
      "7.524610178163958e-06   0   8\n",
      "2.821728816811484e-06   0   3\n",
      "0.0   0   0\n",
      "1.1286915267245937e-05   0   12\n",
      "0.0   0   0\n",
      "1.8811525445409895e-06   0   2\n",
      "0.0   0   0\n",
      "9.405762722704946e-06   0   10\n",
      "1.3168067811786925e-05   0   14\n",
      "6.584033905893463e-06   0   7\n",
      "6.584033905893463e-06   0   7\n",
      "1.598979662859841e-05   0   17\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "1.8811525445409895e-06   0   2\n",
      "6.301861024212315e-05   0   67\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "2.821728816811484e-06   0   3\n",
      "0.0   0   0\n",
      "2.163325426222138e-05   0   23\n",
      "3.009844071265583e-05   0   32\n",
      "7.524610178163958e-06   0   8\n",
      "3.762305089081979e-06   0   4\n",
      "0.0   0   0\n",
      "5.643457633622968e-06   0   6\n",
      "1.034633899497544e-05   0   11\n",
      "1.8811525445409895e-06   0   2\n",
      "9.405762722704947e-07   0   1\n",
      "5.643457633622968e-06   0   6\n",
      "0.0   0   0\n",
      "5.643457633622968e-06   0   6\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "1.8811525445409893e-05   0   20\n",
      "6.113745769758215e-05   0   65\n",
      "2.821728816811484e-06   0   3\n",
      "1.8811525445409893e-05   0   20\n",
      "1.5049220356327916e-05   0   16\n",
      "0.0   0   0\n",
      "3.762305089081979e-06   0   4\n",
      "9.405762722704947e-07   0   1\n",
      "2.821728816811484e-05   0   30\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "4.702881361352473e-06   0   5\n",
      "4.702881361352473e-06   0   5\n",
      "0.0   0   0\n",
      "1.8811525445409895e-06   0   2\n",
      "1.1286915267245937e-05   0   12\n",
      "2.821728816811484e-05   0   30\n",
      "4.702881361352473e-06   0   5\n",
      "3.762305089081979e-06   0   4\n",
      "3.762305089081979e-06   0   4\n",
      "7.524610178163958e-06   0   8\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "6.584033905893463e-06   0   7\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "2.821728816811484e-05   0   30\n",
      "8.465186450434452e-06   0   9\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "9.405762722704947e-07   0   1\n",
      "0.0   0   0\n",
      "4.702881361352473e-06   0   5\n",
      "9.405762722704946e-06   0   10\n",
      "1.9752101717680387e-05   0   21\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "9.405762722704947e-07   0   1\n",
      "0.0   0   0\n",
      "3.762305089081979e-06   0   4\n",
      "0.0   0   0\n",
      "5.643457633622968e-06   0   6\n",
      "9.405762722704947e-07   0   1\n",
      "2.821728816811484e-06   0   3\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "9.405762722704947e-07   0   1\n",
      "0.0   0   0\n",
      "9.405762722704947e-07   0   1\n",
      "0.0   0   0\n",
      "6.584033905893463e-06   0   7\n",
      "0.0   0   0\n",
      "6.584033905893463e-06   0   7\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "4.608823734125424e-05   0   49\n",
      "5.643457633622968e-06   0   6\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "1.8811525445409895e-06   0   2\n",
      "5.643457633622968e-06   0   6\n",
      "2.7276711895844345e-05   0   29\n",
      "8.465186450434452e-06   0   9\n",
      "0.0   0   0\n",
      "1.8811525445409895e-06   0   2\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "2.821728816811484e-06   0   3\n",
      "0.0   0   0\n",
      "2.821728816811484e-06   0   3\n",
      "0.0   0   0\n",
      "6.584033905893463e-06   0   7\n",
      "5.643457633622968e-06   0   6\n",
      "0.0   0   0\n",
      "1.2227491539516431e-05   0   13\n",
      "1.034633899497544e-05   0   11\n",
      "4.702881361352473e-06   0   5\n",
      "0.0   0   0\n",
      "1.410864408405742e-05   0   15\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "5.9256305153041165e-05   0   63\n",
      "4.702881361352473e-06   0   5\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "1.3168067811786925e-05   0   14\n",
      "7.336494923709859e-05   0   78\n",
      "9.405762722704947e-07   0   1\n",
      "0.0   0   0\n",
      "2.821728816811484e-06   0   3\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "5.643457633622968e-06   0   6\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "5.643457633622968e-06   0   6\n",
      "6.584033905893463e-06   0   7\n",
      "5.643457633622968e-06   0   6\n",
      "9.405762722704946e-06   0   10\n",
      "0.0   0   0\n",
      "1.8811525445409895e-06   0   2\n",
      "0.0   0   0\n",
      "3.6682474618549295e-05   0   39\n",
      "0.0   0   0\n",
      "2.821728816811484e-06   0   3\n",
      "0.0   0   0\n",
      "7.336494923709859e-05   0   78\n",
      "1.8811525445409895e-06   0   2\n",
      "9.405762722704947e-07   0   1\n",
      "2.821728816811484e-06   0   3\n",
      "0.0   0   0\n",
      "1.8811525445409895e-06   0   2\n",
      "4.702881361352473e-06   0   5\n",
      "2.821728816811484e-06   0   3\n",
      "3.8563627163090283e-05   0   41\n",
      "5.643457633622968e-06   0   6\n",
      "0.0   0   0\n",
      "1.8811525445409895e-06   0   2\n",
      "1.8811525445409895e-06   0   2\n",
      "2.821728816811484e-06   0   3\n",
      "0.0   0   0\n",
      "5.643457633622968e-06   0   6\n",
      "4.702881361352473e-06   0   5\n",
      "2.821728816811484e-06   0   3\n",
      "0.0   0   0\n",
      "4.702881361352473e-06   0   5\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "3.762305089081979e-06   0   4\n",
      "0.0   0   0\n",
      "3.762305089081979e-06   0   4\n",
      "0.0   0   0\n",
      "1.8811525445409895e-06   0   2\n",
      "0.0   0   0\n",
      "9.405762722704947e-07   0   1\n",
      "0.0   0   0\n",
      "5.831572888077067e-05   0   62\n",
      "9.405762722704947e-07   0   1\n",
      "1.3168067811786925e-05   0   14\n",
      "6.584033905893463e-06   0   7\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "8.465186450434452e-06   0   9\n",
      "2.821728816811484e-06   0   3\n",
      "2.2573830534491874e-05   0   24\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "1.1286915267245937e-05   0   12\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "9.405762722704947e-07   0   1\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "0.0   0   0\n",
      "2.821728816811484e-06   0   3\n",
      "37500\n"
     ]
    }
   ],
   "source": [
    "state_dict = dict()\n",
    "row_list = []\n",
    "TG_population = 35.19 * 10 ** 6\n",
    "for week in range(10,36):\n",
    "    for i in range(important_state_district_data.shape[0]):\n",
    "        state_district_row = important_state_district_data.loc[i]\n",
    "        state = state_district_row['State']\n",
    "        district = state_district_row['District']\n",
    "        \n",
    "        key = (week, state, district)\n",
    "        nrow = dict()        \n",
    "        nrow['Week'] = week\n",
    "        nrow['Origin State'] = state\n",
    "        nrow['Origin District'] = district\n",
    "        nrow['Population'] = state_district_row['Population']\n",
    "        nrow['theta_S_t'] = 0\n",
    "        nrow['theta_C_t'] = 0\n",
    "        nrow['theta_I_t'] = 0\n",
    "        nrow['theta_A_t'] = 0\n",
    "        nrow['theta_R_t'] = 0\n",
    "        nrow['theta_D_t'] = 0\n",
    "        nrow['D_k_Tr_t'] = 0\n",
    "        nrow['D_k_Ro_t'] = 0\n",
    "        nrow['D_k_To_t'] = 0\n",
    "        \n",
    "        state_dict[key] = nrow\n",
    "        row_list.append(nrow)\n",
    "        \n",
    "# multiplier = 10 ** 6\n",
    "multiplier = 1\n",
    "symptomatic_multiplier = 2 * 0.3\n",
    "asymptomatic_multiplier = 20 * 0.7 \n",
    "for i in range(weekly_covid_data.shape[0]):\n",
    "    row = weekly_covid_data.loc[i]\n",
    "    week = row['Week']\n",
    "    state = row['State']\n",
    "    district = row['District']\n",
    "    \n",
    "    if state == \"TELANGANA\":\n",
    "        for tg_district in TG_districts:\n",
    "            key = (week, state, tg_district)\n",
    "            nrow = state_dict[key]\n",
    "            nrow['theta_C_t'] = row['Confirmed'] / TG_population * multiplier\n",
    "            nrow['theta_I_t'] = symptomatic_multiplier * nrow['theta_C_t']\n",
    "            nrow['theta_A_t'] = asymptomatic_multiplier * nrow['theta_C_t']\n",
    "            nrow['theta_T_t'] = nrow['theta_I_t'] + nrow['theta_A_t']\n",
    "            nrow['theta_S_t'] = (1 - nrow['theta_T_t']) * multiplier\n",
    "            nrow['theta_R_t'] = row['Recovered'] / TG_population * multiplier\n",
    "            nrow['theta_D_t'] = row['Deceased'] / TG_population * multiplier\n",
    "    else:\n",
    "        key = (week, state, district)\n",
    "        nrow = state_dict[key]\n",
    "        if district == \"VISAKHAPATANAM\":\n",
    "            print(\"VISAKHAPATANAM\", row['Confirmed'])\n",
    "        nrow['theta_C_t'] = row['Confirmed'] / nrow['Population'] * multiplier\n",
    "        nrow['theta_I_t'] = symptomatic_multiplier * nrow['theta_C_t']\n",
    "        nrow['theta_A_t'] = asymptomatic_multiplier * nrow['theta_C_t']\n",
    "        nrow['theta_T_t'] = nrow['theta_I_t'] + nrow['theta_A_t']\n",
    "        nrow['theta_S_t'] = (1 - nrow['theta_T_t']) * multiplier\n",
    "        nrow['theta_R_t'] = row['Recovered'] / nrow['Population'] * multiplier\n",
    "        nrow['theta_D_t'] = row['Deceased'] / nrow['Population'] * multiplier\n",
    "\n",
    "writeDFToExcel(row_list, 'important_states_weekly_parameters.xlsx', 'Weekly Parameters') \n",
    "\n",
    "influx_row_list = []\n",
    "for i in range(weekly_influx_data.shape[0]):\n",
    "    row = weekly_influx_data.loc[i]\n",
    "    week = row['Week']\n",
    "    if week >= 35 or 10 > week:\n",
    "        continue\n",
    "    state = row['Origin State']\n",
    "    district = row['Origin District']\n",
    "    key = (week, state, district)\n",
    "    nrow = state_dict[key]\n",
    "    influx_row = dict()\n",
    "    \n",
    "    influx_row['Week'] = week\n",
    "    influx_row['Origin State'] = state\n",
    "    influx_row['Origin District'] = district\n",
    "    influx_row['Destination District'] = row['Destination District']\n",
    "    influx_row['Population'] = nrow['Population']\n",
    "    influx_row['theta_S_t'] = nrow['theta_S_t']\n",
    "    influx_row['theta_C_t'] = nrow['theta_C_t']\n",
    "    influx_row['theta_I_t'] = nrow['theta_I_t']\n",
    "    influx_row['theta_A_t'] = nrow['theta_A_t']\n",
    "    influx_row['theta_T_t'] = nrow['theta_I_t'] + nrow['theta_A_t']\n",
    "    influx_row['theta_R_t'] = nrow['theta_R_t']\n",
    "    influx_row['theta_D_t'] = nrow['theta_D_t']\n",
    "    influx_row['D_k_Tr_t'] = row['Train Passengers'] / nrow['Population'] * multiplier\n",
    "    influx_row['D_k_Ro_t'] = row['Road Passengers'] / nrow['Population'] * multiplier\n",
    "    influx_row['D_k_To_t'] = influx_row['D_k_Tr_t'] + influx_row['D_k_Ro_t'] * multiplier\n",
    "    influx_row_list.append(influx_row)\n",
    "    if district == \"VISAKHAPATANAM\":\n",
    "#         print(\"VISAKHAPATANAM\", row['Confirmed'])\n",
    "        print(influx_row['D_k_To_t'], \" \",row['Train Passengers'],\" \",row['Road Passengers'])\n",
    "\n",
    "writeDFToExcel(influx_row_list, 'influx_district_state_parameters.xlsx', 'Weekly Parameters') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
